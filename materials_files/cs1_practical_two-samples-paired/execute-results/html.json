{
  "hash": "6b0803067a3aeac00dfe34f486b92eab",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Paired data\"\n---\n \n\n::: {.cell}\n\n:::\n\n\n\n::: {.cell}\n\n:::\n\n\n::: {.callout-tip}\n#### Learning outcomes\n\n**Questions**\n\n- When do I perform a paired two-sample test?\n- What are the assumptions?\n- How do I interpret and present the results of the test?\n- How do I deal with paired non-normal data?\n\n**Objectives**\n\n- Set out your hypothesis for comparing two paired samples of continuous data\n- Be able to summarise and visualise the data\n- Understand and assess the underlying assumptions of the test\n- Perform a paired two-sample t-test\n- Be able to interpret and report the results\n- Be able to do these steps on non-normal data\n\n:::\n\nA paired t-test is used when we have two samples of continuous data that can be paired (examples of these sort of data would be weights of individuals before and after a diet). This test is applicable if the number of paired points within the samples is large (\\>30) or, if the number of points is small, then this test also works when the parent distributions are normally distributed.\n\nThere is the assumption that each pair within the data is independent of each other.\n\n## Libraries and functions\n\n::: {.callout-note collapse=\"true\"}\n## Click to expand\n\n::: {.panel-tabset group=\"language\"}\n## R\n\n### Libraries\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# A collection of R packages designed for data science\nlibrary(tidyverse)\n\n# Converts stats functions to a tidyverse-friendly format\nlibrary(rstatix)\n```\n:::\n\n\n### Functions\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Performs a one-sample t-test, Student's t-test\n# and Welch's t-test in later sections\nrstatix::t_test()\n\n# Performs a Shapiro-Wilk test for normality\nstats::shapiro.test()\n\n# Performs one and two sample Wilcoxon tests\nrstatix::wilcox_test()\n\n# Plots a Q-Q plot for comparison with a normal distribution\nggplot2::stat_qq()\n\n# Adds a comparison line to the Q-Q plot\nggplot2::stat_qq_line()\n\n# Plots jittered points by adding a small amount of random\n# variation to each point, to handle overplotting\nggplot2::geom_jitter()\n\n# Computes summary statistics                         \nrstatix::get_summary_stats() \n\n# \"Widens\" the data, increasing the number of columns\ntidyr::pivot_wider()\n```\n:::\n\n\n## Python\n\n### Libraries\n\n\n::: {.cell}\n\n```{.python .cell-code}\n# A Python data analysis and manipulation tool\nimport pandas as pd\n\n# Simple yet exhaustive stats functions.\nimport pingouin as pg\n\n# Python equivalent of `ggplot2`\nfrom plotnine import *\n```\n:::\n\n\n### Functions\n\n\n::: {.cell}\n\n```{.python .cell-code}\n# Return reshaped DataFrame organised by given index / column values\npandas.DataFrame.pivot()\n\n# Reads in a .csv file\npandas.DataFrame.read_csv()\n\n# Performs the Shapiro-Wilk test for normality\npingouin.normality()\n\n# Performs a t-test\npingouin.ttest()\n\n# Performs Wilcoxon signed rank test\npingouin.wilcoxon()\n\n# Plots a Q-Q plot for comparison with a normal distribution\nplotnine.stats.stat_qq()\n\n# Adds a comparison line to the Q-Q plot\nplotnine.stats.stat_qq_line()\n```\n:::\n\n                                 |\n:::\n:::\n\n## Data and hypotheses\n\nFor example, suppose we measure the cortisol levels in 20 adult females (nmol/l) first thing in the morning and again in the evening. We want to test whether the cortisol levels differs between the two measurement times. We will initially form the following null and alternative hypotheses:\n\n-   $H_0$: There is no difference in cortisol level between times ($\\mu M = \\mu E$)\n-   $H_1$: There is a difference in cortisol levels between times ($\\mu M \\neq \\mu E$)\n\nWe use a two-sample, two-tailed paired t-test to see if we can reject the null hypothesis.\n\n-   We use a **two-sample** test because we now have two samples\n-   We use a **two-tailed** t-test because we want to know if our data suggest that the true (population) means are different from one another rather than that one mean is specifically bigger or smaller than the other\n-   We use a **paired** test because each data point in the first sample can be linked to another data point in the second sample by a connecting factor\n-   We're using a **t-test** because we assume that the underlying population is normally distributed (We'll check this in a bit)\n\nThe data are stored in a tidy format in the file `data/CS1-twopaired.csv`.\n\n::: {.panel-tabset group=\"language\"}\n## R\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# load the data\ncortisol <- read_csv(\"data/CS1-twopaired.csv\")\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nRows: 40 Columns: 3\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (1): time\ndbl (2): patient_id, cortisol\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n```\n\n\n:::\n\n```{.r .cell-code}\n# have a look at the data\ncortisol\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 40 × 3\n   patient_id time    cortisol\n        <dbl> <chr>      <dbl>\n 1          1 morning     311.\n 2          2 morning     146.\n 3          3 morning     297 \n 4          4 morning     271.\n 5          5 morning     268.\n 6          6 morning     264.\n 7          7 morning     358.\n 8          8 morning     316.\n 9          9 morning     336.\n10         10 morning     221.\n# ℹ 30 more rows\n```\n\n\n:::\n:::\n\n\n## Python\n\n\n::: {.cell}\n\n```{.python .cell-code}\n# load the data\ncortisol_py = pd.read_csv('data/CS1-twopaired.csv')\n\n# inspect the data\ncortisol_py.head()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n   patient_id     time  cortisol\n0           1  morning     310.6\n1           2  morning     146.1\n2           3  morning     297.0\n3           4  morning     270.9\n4           5  morning     267.5\n```\n\n\n:::\n:::\n\n:::\n\nWe can see that the data frame consists of three columns:\n\n1.  `patient_id`, a unique ID for each patient\n2.  `time` when the cortisol level was measured\n3.  `cortisol`, which contains the measured value.\n\nFor each `patient_id` there are two measurements: one in the morning and one in the afternoon.\n\n## Summarise and visualise\n\nIt's always a good idea to visualise your data, so let's do that.\n\n::: {.panel-tabset group=\"language\"}\n## R\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# create a boxplot\nggplot(cortisol,\n       aes(x = time, y = cortisol)) +\n  geom_boxplot() +\n  geom_jitter(width = 0.05) +\n  ylab(\"Cortisol level (nmol/l)\")\n```\n\n::: {.cell-output-display}\n![](cs1_practical_two-samples-paired_files/figure-html/unnamed-chunk-9-1.png){width=672}\n:::\n:::\n\n\nHere we use also visualise the actual data points, to get a sense of how these data are spread out. To avoid overlapping the data points (try using `geom_point()` instead of `geom_jitter()`), we jitter the data points. What `geom_jitter()` does is add a small amount of variation to each point.\n\n## Python\n\n\n::: {.cell}\n\n```{.python .cell-code}\np = (ggplot(cortisol_py,\n        aes(x = \"time\",\n            y = \"cortisol\")) +\n     geom_boxplot() +\n     geom_jitter(width = 0.05) +\n     ylab(\"Cortisol level (nmol/l)\"))\n\np.show()\n```\n\n::: {.cell-output-display}\n![](cs1_practical_two-samples-paired_files/figure-html/unnamed-chunk-10-1.png){width=614}\n:::\n:::\n\n:::\n\nHowever, this plot does not capture how the cortisol level of each *individual* subject has changed though. We can explore the individual changes between morning and evening by looking at the *differences* between the two times of measurement for each patient.\n\nTo do this, we need to put our data into a wide format, so we can calculate the change in cortisol level for each patient.\n\n::: {.panel-tabset group=\"language\"}\n## R\n\nIn `tidyverse` we can use the `pivot_wider()` function.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# calculate the difference between evening and morning values\ncortisol_diff <- cortisol %>%\n  pivot_wider(id_cols = patient_id,\n              names_from = time,\n              values_from = cortisol) %>% \n  mutate(cortisol_change = evening - morning)\n\ncortisol_diff\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 20 × 4\n   patient_id morning evening cortisol_change\n        <dbl>   <dbl>   <dbl>           <dbl>\n 1          1    311.   273.            -37.4\n 2          2    146.    65.7           -80.4\n 3          3    297    257.            -40.4\n 4          4    271.   321              50.1\n 5          5    268.    80.3          -187. \n 6          6    264.   379.            116. \n 7          7    358.   163.           -195. \n 8          8    316.   294.            -22  \n 9          9    336.   140.           -196. \n10         10    221.   231.             10.4\n11         11    366    131.           -235. \n12         12    256.   114.           -142. \n13         13    432.   217.           -215. \n14         14    208.    60.1          -148. \n15         15    324.   199.           -125. \n16         16    388.   170.           -218. \n17         17    332    160.           -172. \n18         18    414.   179.           -235. \n19         19    405.   286            -119. \n20         20    356.   226.           -130. \n```\n\n\n:::\n:::\n\n\nThere are three arguments in `pivot_wider()`:\n\n1. `id_cols = patient_id` tells it that each observational unit is determined by `patient_id`\n2. `names_from = time` says that there will be new columns, with names from the `time` column (in this case, there are two values in there, `morning` and `evening`)\n3. `values_from = cortisol` populates the new columns with the values coming from the `cortisol` column\n\nLastly, we create a new column `cortisol_change` that contains the difference between the `evening` and `morning` measurements.\n\nAfter this we can plot our data:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# plot the data\nggplot(cortisol_diff,\n       aes(y = cortisol_change)) +\n  geom_boxplot() +\n  ylab(\"Change in cortisol (nmol/l)\")\n```\n\n::: {.cell-output-display}\n![](cs1_practical_two-samples-paired_files/figure-html/unnamed-chunk-12-1.png){width=672}\n:::\n:::\n\n\nThe differences in cortisol levels appear to be very much less than zero, meaning that the evening cortisol levels appear to be much lower than the morning ones. As such we would expect that the test would give a pretty significant result.\n\nAn alternative representation would be to plot the data points for both evening and morning and connect them by patient:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# plot cortisol levels by patient\nggplot(cortisol,\n       aes(x = time,\n           y = cortisol,\n           group = patient_id)) +\n  geom_point() +\n  geom_line()\n```\n\n::: {.cell-output-display}\n![](cs1_practical_two-samples-paired_files/figure-html/unnamed-chunk-13-1.png){width=672}\n:::\n:::\n\n\nThis gives a similar picture to what the boxplot was telling us, that for most patients the cortisol levels are higher in the morning than in the evening.\n\n## Python\n\n\n::: {.cell}\n\n```{.python .cell-code}\n# reformat the data into a 'wide' format\ncortisol_diff_py = pd.pivot(cortisol_py, index = \"patient_id\", columns = \"time\", values = \"cortisol\")\n\n# add a new column with difference between\n# evening and morning cortisol levels\ncortisol_diff_py[\"cortisol_change\"] = cortisol_diff_py[\"evening\"].subtract(cortisol_diff_py[\"morning\"])\n      \n# have a look at the format\ncortisol_diff_py.head()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\ntime        evening  morning  cortisol_change\npatient_id                                   \n1             273.2    310.6            -37.4\n2              65.7    146.1            -80.4\n3             256.6    297.0            -40.4\n4             321.0    270.9             50.1\n5              80.3    267.5           -187.2\n```\n\n\n:::\n:::\n\n\nAfter this we can plot our data:\n\n\n::: {.cell}\n\n```{.python .cell-code}\n# plot the data\np = (ggplot(cortisol_diff_py,\n        aes(x = \"1\",\n            y = \"cortisol_change\")) +\n     geom_boxplot() +\n     ylab(\"Change in cortisol (nmol/l)\"))\n\np.show()\n```\n\n::: {.cell-output-display}\n![](cs1_practical_two-samples-paired_files/figure-html/unnamed-chunk-15-1.png){width=614}\n:::\n:::\n\n\nThe differences in cortisol levels appear to be very much less than zero, meaning that the evening cortisol levels appear to be much lower than the morning ones. As such we would expect that the test would give a pretty significant result.\n\nAn alternative representation would be to plot the data points for both evening and morning and connect them by patient:\n\n\n::: {.cell}\n\n```{.python .cell-code}\n# plot cortisol levels by patient\np = (ggplot(cortisol_py,\n        aes(x = \"time\",\n            y = \"cortisol\",\n            group = \"patient_id\")) +\n     geom_point() +\n     geom_line())\n\np.show()\n```\n\n::: {.cell-output-display}\n![](cs1_practical_two-samples-paired_files/figure-html/unnamed-chunk-16-3.png){width=614}\n:::\n:::\n\n\nThis gives a similar picture to what the boxplot was telling us, that for most patients the cortisol levels are higher in the morning than in the evening.\n:::\n\n## Assumptions\n\nYou will do this in the exercise!\n\n## Implement and interpret the test\n\nPerform a two-sample, two-tailed, paired t-test:\n\n::: {.panel-tabset group=\"language\"}\n## R\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# perform the test\nt_test(cortisol ~ time,\n       alternative = \"two.sided\",\n       paired = TRUE,\n       data = cortisol)\n```\n:::\n\n\n-   The first argument must be in the formula format: `response ~ predictor`\n-   The `alternative` argument gives the type of alternative hypothesis and must be one of `two.sided`, `greater` or `less`\n-   The `paired = TRUE` argument indicates that the data are paired\n\nFrom our perspective the value of interest in the output is the `p` (5.29\\times 10^{-5}).\n\n## Python\n\nTo perform a paired t-test we can use the same `pg.ttest()` as before, but set the argument `paired = True`.\n\nAnnoyingly, the output is not entirely visible because the data frame is too wide. To deal with that, we can simply transpose it with `transpose()`\n\n\n::: {.cell}\n\n```{.python .cell-code}\npg.ttest(cortisol_diff_py[\"evening\"],\n         cortisol_diff_py[\"morning\"],\n         alternative = \"two-sided\",\n         paired = True).transpose()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n                        T-test\nT                     -5.18329\ndof                         19\nalternative          two-sided\np-val                 0.000053\nCI95%        [-162.96, -69.21]\ncohen-d               1.434359\nBF10                   491.599\npower                  0.99998\n```\n\n\n:::\n:::\n\n\nFrom our perspective the value of interest is the `p-val`.\n:::\n\nSince the p-value = 5.29 $\\times$ 10<sup>-5</sup>) and thus substantially less than 0.05 we can reject the null hypothesis and state:\n\n> A two-tailed, paired t-test indicated that the average cortisol level in adult females differed significantly between the morning (313.5 nmol/l) and the evening (197.4 nmol/l, p = 5.3 \\* 10<sup>-5</sup>).\n\n## Dealing with non-normal data\n\nThe example above assumes that the paired data come from parent distributions that are normal. As we've seen before, we may have data where we can't rely on that assumption. Fortunately, there is very little that we need to change in our approach if we want to analyse paired data that violate the assumption of normality.\n\n### Data and hypotheses\n\nUsing the `cortisol` data from before we form the following null and alternative hypotheses:\n\n-   $H_0$: The median of the difference in cortisol levels between the two groups is 0 $(\\mu M = \\mu E)$\n-   $H_1$: The median of the difference in cortisol levels between the two groups is not 0 $(\\mu M \\neq \\mu E)$\n\nWe use a two-tailed Wilcoxon signed rank test to see if we can reject the null hypothesis.\n\n### Summarise and visualise\n\nAlready implemented previously.\n\n### Assumptions\n\nThese have been checked previously.\n\n### Implement and interpret the test\n\nPerform a two-tailed, Wilcoxon signed rank test:\n\n::: {.panel-tabset group=\"language\"}\n## R\n\n\n::: {.cell}\n\n```{.r .cell-code}\nwilcox_test(cortisol ~ time,\n            alternative = \"two.sided\",\n            paired = TRUE,\n            data = cortisol)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 1 × 7\n  .y.      group1  group2     n1    n2 statistic        p\n* <chr>    <chr>   <chr>   <int> <int>     <dbl>    <dbl>\n1 cortisol evening morning    20    20        13 0.000168\n```\n\n\n:::\n:::\n\n\n-   The first argument must be in the formula format: `response ~ predictor`\n-   The `alternative` argument gives the type of alternative hypothesis and must be one of `two.sided`, `greater` or `less`\n- The `paired = TRUE` argument indicates that the data are paired\n\n## Python\n\nWe'll use the wide format data set that we created previously:\n\n\n::: {.cell}\n\n```{.python .cell-code}\npg.wilcoxon(x = cortisol_diff_py[\"evening\"],\n            y = cortisol_diff_py[\"morning\"],\n            alternative = \"two-sided\",\n            correction = True)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n          W-val alternative     p-val      RBC  CLES\nWilcoxon   13.0   two-sided  0.000168 -0.87619  0.16\n```\n\n\n:::\n:::\n\n:::\n\nThe p-value is given in the `p` column (p-value = 0.000168). Given that this is less than 0.05 we can still reject the null hypothesis.\n\n> A two-tailed, Wilcoxon signed rank test indicated that the median cortisol level in adult females differed significantly between the morning (320.5 nmol/l) and the evening (188.9 nmol/l, p = 0.00017).\n\n## Exercises\n\n### Cortisol levels {#sec-exr_cortisol}\n\n:::{.callout-exercise}\n\n{{< level 2 >}}\n\nCheck the assumptions necessary for this this paired t-test. Was a paired t-test an appropriate test?\n\n::: {.callout-tip collapse=\"true\"}\n## Answer\n\nWe actually don't care too much about the distributions of the individual groups. Instead we care about the properties of the **differences**. So for a paired t-test to be valid for this data set, we need the differences between the morning and evening values to be normally distributed.\n\nLet's check this with the Shapiro-Wilk test and Q-Q plots, using the wide data frames we created earlier.\n\n::: {.panel-tabset group=\"language\"}\n## R\n\nPerform Shapiro-Wilk test:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# perform Shapiro-Wilk test on cortisol differences\nshapiro.test(cortisol_diff$cortisol_change)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tShapiro-Wilk normality test\n\ndata:  cortisol_diff$cortisol_change\nW = 0.92362, p-value = 0.1164\n```\n\n\n:::\n:::\n\n\nCreate Q-Q plot:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# create the Q-Q plot\nggplot(cortisol_diff,\n       aes(sample = cortisol_change)) +\n  stat_qq() +\n  stat_qq_line(colour = \"blue\")\n```\n\n::: {.cell-output-display}\n![](cs1_practical_two-samples-paired_files/figure-html/unnamed-chunk-22-1.png){width=672}\n:::\n:::\n\n\n## Python\n\nPerform Shapiro-Wilk test:\n\n\n::: {.cell}\n\n```{.python .cell-code}\n# perform Shapiro-Wilk test on cortisol differences\npg.normality(cortisol_diff_py[\"cortisol_change\"])\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n                        W      pval  normal\ncortisol_change  0.923622  0.116355    True\n```\n\n\n:::\n:::\n\n\nCreate Q-Q plot:\n\n\n::: {.cell}\n\n```{.python .cell-code}\n# create the Q-Q plot\np = (ggplot(cortisol_diff_py,\n        aes(sample = \"cortisol_change\")) +\n     stat_qq() +\n     stat_qq_line(colour = \"red\"))\n\np.show()\n```\n\n::: {.cell-output-display}\n![](cs1_practical_two-samples-paired_files/figure-html/unnamed-chunk-24-1.png){width=614}\n:::\n:::\n\n:::\n\nThe Shapiro-Wilk test says that the data are normal enough and whilst the Q-Q plot is mostly fine, there is some suggestion of snaking at the bottom left. I'm actually OK with this because the suggestion of snaking is actually only due to a single point (the last point on the left). If you cover that point up with your thumb (or finger of your choice) then the remaining points in the Q-Q plot look pretty darn good, and so the suggestion of snaking is actually driven by only a single point (which can happen by chance). As such I'm happy that the assumption of normality is well-met in this case. This **single point** check is a useful thing to remember when assessing diagnostic plots.\n\nSo, yep, a paired t-test is appropriate for this data set.\n:::\n:::\n\n### Deer legs {#sec-exr_deerlegs}\n\n:::{.callout-exercise}\n\n{{< level 2 >}}\n\nUsing the following data on deer legs (yes, really!), test the null hypothesis that the fore and hind legs of the deer in this data set are the same length.\n\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 10 × 2\n   hindleg foreleg\n     <dbl>   <dbl>\n 1     142     138\n 2     140     136\n 3     144     147\n 4     144     139\n 5     142     143\n 6     146     141\n 7     149     143\n 8     150     145\n 9     142     136\n10     148     146\n```\n\n\n:::\n:::\n\n\nDo these results provide any evidence to suggest that fore- and hind-leg length differ in deer?\n\n1.  Write down the null and alternative hypotheses\n2.  Import the data from `data/CS1-deer.csv`\n3.  Summarise and visualise the data\n4.  Check normality\n5.  Discuss with your (virtual) neighbour which test is most appropriate?\n6.  Perform the test\n7.  Write down a sentence that summarises the results that you have found\n\n::: {.callout-tip collapse=\"true\"}\n## Answer\n\n#### Hypotheses\n\n$H_0$ : foreleg average (mean or median) $=$ hindleg average (mean or median)\n\n$H_1$ : foreleg average $\\neq$ hindleg average\n\n#### Import data, summarise and visualise\n\nFirst of all, we need to load in the data.\n\n::: {.panel-tabset group=\"language\"}\n## R\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# load the data\ndeer <- read_csv(\"data/CS1-deer.csv\")\n\n# have a look\ndeer\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 20 × 3\n      id leg     length\n   <dbl> <chr>    <dbl>\n 1     1 hindleg    142\n 2     2 hindleg    140\n 3     3 hindleg    144\n 4     4 hindleg    144\n 5     5 hindleg    142\n 6     6 hindleg    146\n 7     7 hindleg    149\n 8     8 hindleg    150\n 9     9 hindleg    142\n10    10 hindleg    148\n11     1 foreleg    138\n12     2 foreleg    136\n13     3 foreleg    147\n14     4 foreleg    139\n15     5 foreleg    143\n16     6 foreleg    141\n17     7 foreleg    143\n18     8 foreleg    145\n19     9 foreleg    136\n20    10 foreleg    146\n```\n\n\n:::\n:::\n\n\nThe ordering of the data is important here; the first hind leg row corresponds to the first fore leg row, the second to the second and so on. To indicate this we use an `id` column, where each observation has a unique ID.\n\nLet's look at the data and see what it tells us.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# summarise the data\nsummary(deer)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n       id           leg                length     \n Min.   : 1.0   Length:20          Min.   :136.0  \n 1st Qu.: 3.0   Class :character   1st Qu.:140.8  \n Median : 5.5   Mode  :character   Median :143.0  \n Mean   : 5.5                      Mean   :143.1  \n 3rd Qu.: 8.0                      3rd Qu.:146.0  \n Max.   :10.0                      Max.   :150.0  \n```\n\n\n:::\n:::\n\n\nWe can also summarise some of the main summary statistics for each type of `leg`. We don't need summary statistics for the `id` column, so we unselect it with `select(-id)`.\n\nTo make life easy we use the `get_summary_stats()` function from the `rstatix` package. Have a look at the help function to see what kind of summary statistics it can produce. In this case I'm using the `type = \"common\"` option to specify that I want to find commonly used statistics (e.g. sample number, min, max, median, mean etc.)\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# or even summarise by leg type\ndeer %>% \n  select(-id) %>% \n  group_by(leg) %>% \n  get_summary_stats(type = \"common\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 2 × 11\n  leg     variable     n   min   max median   iqr  mean    sd    se    ci\n  <chr>   <fct>    <dbl> <dbl> <dbl>  <dbl> <dbl> <dbl> <dbl> <dbl> <dbl>\n1 foreleg length      10   136   147    142  6.25  141.  4.03  1.27  2.88\n2 hindleg length      10   140   150    144  5.5   145.  3.40  1.08  2.43\n```\n\n\n:::\n:::\n\n\nVisualising the data is often more useful:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# we can also visualise the data\nggplot(deer,\n       aes(x = leg, y = length)) +\n    geom_boxplot()\n```\n\n::: {.cell-output-display}\n![](cs1_practical_two-samples-paired_files/figure-html/unnamed-chunk-29-1.png){width=672}\n:::\n:::\n\n\nAll of this suggests that there might be a difference between the legs, with hind legs being longer than forelegs. However, this representation obscures the fact that we have *paired* data. What we really need to look at is the _difference_ in leg length for each observation:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# create a data set that contains the difference in leg length\nleg_diff <- deer %>% \n  pivot_wider(id_cols = id,\n              names_from = leg,\n              values_from = length) %>% \n  mutate(leg_diff = hindleg - foreleg)\n```\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# plot the difference in leg length\nggplot(leg_diff,\n       aes(y = leg_diff)) +\n  geom_boxplot()\n```\n\n::: {.cell-output-display}\n![](cs1_practical_two-samples-paired_files/figure-html/unnamed-chunk-31-1.png){width=672}\n:::\n:::\n\n\nAdditionally, we can also plot the data by observation:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# plot the data by observation\nggplot(deer,\n       aes(x = leg, y = length, group = id)) +\n  geom_point() +\n  geom_line()\n```\n\n::: {.cell-output-display}\n![](cs1_practical_two-samples-paired_files/figure-html/unnamed-chunk-32-1.png){width=672}\n:::\n:::\n\n\n## Python\n\n\n::: {.cell}\n\n```{.python .cell-code}\n# load the data\ndeer_py = pd.read_csv(\"data/CS1-deer.csv\")\n\n# have a look\ndeer_py.head()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n   id      leg  length\n0   1  hindleg     142\n1   2  hindleg     140\n2   3  hindleg     144\n3   4  hindleg     144\n4   5  hindleg     142\n```\n\n\n:::\n:::\n\n\nThe ordering of the data is important here; the first hind leg row corresponds to the first fore leg row, the second to the second and so on. To indicate this we use an `id` column, where each observation has a unique ID.\n\nLet's look at the data and see what we can see.\n\n\n::: {.cell}\n\n```{.python .cell-code}\n# summarise the data\ndeer_py.describe()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n              id      length\ncount  20.000000   20.000000\nmean    5.500000  143.050000\nstd     2.946898    4.006245\nmin     1.000000  136.000000\n25%     3.000000  140.750000\n50%     5.500000  143.000000\n75%     8.000000  146.000000\nmax    10.000000  150.000000\n```\n\n\n:::\n:::\n\n\nWe can also summarise by leg type:\n\n\n::: {.cell}\n\n```{.python .cell-code}\ndeer_py.groupby(\"leg\")[\"length\"].describe()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n         count   mean       std    min     25%    50%    75%    max\nleg                                                                \nforeleg   10.0  141.4  4.033196  136.0  138.25  142.0  144.5  147.0\nhindleg   10.0  144.7  3.400980  140.0  142.00  144.0  147.5  150.0\n```\n\n\n:::\n:::\n\n\nIt might be more helpful to look at the *difference* in leg length. In order to calculate that, we need to reformat our data into a 'wide' format first:\n\n\n::: {.cell}\n\n```{.python .cell-code}\n# reformat the data into a 'wide' format\nleg_diff_py = pd.pivot(deer_py,\n                       index = \"id\",\n                       columns = \"leg\",\n                       values = \"length\")\n\n# have a look at the format\nleg_diff_py.head()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nleg  foreleg  hindleg\nid                   \n1        138      142\n2        136      140\n3        147      144\n4        139      144\n5        143      142\n```\n\n\n:::\n:::\n\n\nNext, we can add a new column `leg_diff` that contains the leg difference:\n\n\n::: {.cell}\n\n```{.python .cell-code}\n# add a new column with difference between\n# hind and fore leg length\nleg_diff_py[\"leg_diff\"] = leg_diff_py[\"hindleg\"].subtract(leg_diff_py[\"foreleg\"])\n \n```\n:::\n\n\nFinally, we can visualise this:\n\n\n::: {.cell}\n\n```{.python .cell-code}\n# we can also visualise the data\np = (ggplot(leg_diff_py,\n        aes(x = \"1\",\n            y = \"leg_diff\")) +\n     geom_boxplot())\n\np.show()\n```\n\n::: {.cell-output-display}\n![](cs1_practical_two-samples-paired_files/figure-html/unnamed-chunk-38-1.png){width=614}\n:::\n:::\n\n\nAll of this suggests that there might be a difference between the legs, with hind legs being longer than forelegs. However, this representation obscures the fact that we have *paired* data. What we really need to look at is the difference in leg length for each observation:\n\n\n::: {.cell}\n\n```{.python .cell-code}\n# plot paired observations\np = (ggplot(deer_py,\n        aes(x = \"leg\",\n            y = \"length\",\n            group = \"id\")) +\n     geom_point() +\n     geom_line())\n\np.show()\n```\n\n::: {.cell-output-display}\n![](cs1_practical_two-samples-paired_files/figure-html/unnamed-chunk-39-3.png){width=614}\n:::\n:::\n\n:::\n\nAll of this gives us a much clearer picture. It looks as though the hindlegs are about 4 cm longer than the forelegs, on average. It also suggests that our leg differences might not be normally distributed (the data look a bit skewed in the boxplot).\n\n#### Assumptions\n\nWe need to consider the distribution of the *difference* in leg lengths rather than the individual distributions.\n\n::: {.panel-tabset group=\"language\"}\n## R\n\nShapiro-Wilk test:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# perform Shapiro-Wilk test on leg differences\nshapiro.test(leg_diff$leg_diff)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tShapiro-Wilk normality test\n\ndata:  leg_diff$leg_diff\nW = 0.81366, p-value = 0.02123\n```\n\n\n:::\n:::\n\n\nQ-Q plot:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# create a Q-Q plot\nggplot(leg_diff,\n       aes(sample = leg_diff)) +\n  stat_qq() +\n  stat_qq_line(colour = \"blue\")\n```\n\n::: {.cell-output-display}\n![](cs1_practical_two-samples-paired_files/figure-html/unnamed-chunk-41-1.png){width=672}\n:::\n:::\n\n\n## Python\n\nShapiro-Wilk test:\n\n\n::: {.cell}\n\n```{.python .cell-code}\n# perform Shapiro-Wilk test on leg length differences\npg.normality(leg_diff_py[\"leg_diff\"])\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n                 W      pval  normal\nleg_diff  0.813656  0.021235   False\n```\n\n\n:::\n:::\n\n\nCreate the Q-Q plot:\n\n\n::: {.cell}\n\n```{.python .cell-code}\n# create the Q-Q plot\np = (ggplot(leg_diff_py,\n        aes(sample = \"leg_diff\")) +\n     stat_qq() +\n     stat_qq_line(colour = \"red\"))\n\np.show()\n```\n\n::: {.cell-output-display}\n![](cs1_practical_two-samples-paired_files/figure-html/unnamed-chunk-43-1.png){width=614}\n:::\n:::\n\n:::\n\nBoth our Shapiro-Wilk test and our Q-Q plot suggest that the difference data aren't normally distributed, which rules out a paired t-test. We should therefore consider a paired Wilcoxon signed rank test next. Remember that this test requires that the distribution of differences be of a similar shape, whereas our box plot from before suggested that the data were very much skewed.\n\nThis means that we're not able to perform a paired Wilcoxon signed rank test either!\n\n#### Conclusions\n\nSo, frustratingly, neither of the tests at our disposal are appropriate for this data set. The differences in fore leg and hind leg lengths are neither normal enough for a paired t-test nor are they symmetric enough for a Wilcoxon signed rank test. We also don't have enough data to just use the t-test (we'd need more than 30 points or so). So what do we do in this situation? Well, the answer is that there aren't actually any traditional statistical tests that are valid for this data set as it stands!\n\nThere are two options available to someone:\n\n1.  try transforming the raw data (take logs, square root, reciprocals) and hope that one of them leads to a modified data set that satisfies the assumptions of one of the tests we've covered, or\n2.  use a permutation test approach (which would work but is beyond the scope of this course).\n\nThe reason I included this example in the first practical is purely to illustrate how a very simple data set with an apparently clear message (leg lengths differ within deer) can be intractable. You don't need to have very complex data sets before you go beyond the capabilities of classical statistics.\n\nAs Jeremy Clarkson [would put it](https://www.quotes.net/mquote/941330):\n\n> And on that bombshell, it's time to end. Goodnight!\n\n:::\n:::\n\n## Summary\n\n::: {.callout-tip}\n#### Key points\n\n-   Paired t-tests are used when you have two paired samples of continuous data, which are normally distributed\n-   A good way of assessing the assumption of normality is by checking the data against a Q-Q plot\n-   The Wilcoxon signed rank test is used when you have two paired samples of continuous data, which are not normally distributed.\n:::\n\n",
    "supporting": [
      "cs1_practical_two-samples-paired_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}