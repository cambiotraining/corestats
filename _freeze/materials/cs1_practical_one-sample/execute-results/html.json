{
  "hash": "f921d4dff19d85d89f0a1ded375e3bfd",
  "result": {
    "markdown": "---\ntitle: \"One-sample data\"\n---\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n\n:::\n\n\n::: {.callout-tip}\n#### Learning outcomes\n\n**Questions**\n\n-   When do I perform a one-sample test?\n-   What are the assumptions?\n-   How do I interpret and present the results of the test?\n-   How do I deal with non-normal data?\n\n**Objectives**\n\n-   Set out your hypothesis for single sample continuous data\n-   Be able to summarise and visualise the data\n-   Understand and assess the underlying assumptions of the test\n-   Perform a one-sample t-test\n-   Be able to interpret and report the results\n-   Be able to do these steps on non-normal data\n:::\n\n## Libraries and functions\n\n::: {.callout-note collapse=\"true\"}\n## Click to expand\n\n::: {.panel-tabset group=\"language\"}\n## R\n\n### Libraries\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# A collection of R packages designed for data science\nlibrary(tidyverse)\n```\n:::\n\n\n### Functions\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Performs a one-sample t-test, Student's t-test and Welch's t-test in later sections\nstats::t.test()\n\n# Performs a Shapiro-Wilk test for normality\nstats::shapiro.test()\n\n# Performs one and two sample Wilcoxon tests\nstats::wilcox.test()\n\n# Plots a Q-Q plot for comparison with a normal distribution\nggplot2::stat_qq()\n\n# Adds a comparison line to the Q-Q plot\nggplot2::stat_qq_line()\n```\n:::\n\n\n## Python\n\n| Libraries  | Description                                                              |\n|:-------------------|:---------------------------------------------------|\n| `plotnine` | The Python equivalent of `ggplot2`.                                      |\n| `pandas`   | A Python data analysis and manipulation tool.                            |\n| `pingouin` | A Python module developed to have simple yet exhaustive stats functions. |\n\n| Functions                                                                                     | Description                                                 |\n|:--------------------------|:--------------------------------------------|\n| [`pingouin.normality()`](https://pingouin-stats.org/generated/pingouin.normality.html)        | Performs the Shapiro-Wilk test for normality.               |\n| [`pingouin.ttest()`](https://pingouin-stats.org/generated/pingouin.ttest.html#pingouin.ttest) | Performs a t-test                                           |\n| [`pingouin.wilcoxon()`](https://pingouin-stats.org/generated/pingouin.wilcoxon.html#pingouin.wilcoxon) | Wilcoxon signed rank test. |\n| `plotnine.stats.stat_qq()`                                                                    | Plots a Q-Q plot for comparison with a normal distribution. |\n| `plotnine.stats.stat_qq_line()`                                                               | Adds a comparison line to the Q-Q plot.                     |\n:::\n:::\n\n## Purpose and aim\n\nOne sample tests are used when we have a single sample of continuous data. It is used to find out if the sample came from a parent distribution with a given mean (or median). This essentially boils down to finding out if the sample mean (or median) is \"close enough\" to our hypothesised parent population mean (or median). So, in the figure below, we could use these tests to see what the probability is that the sample of ten points comes from the distribution plotted above it i.e. a population with a mean of 20 mm.\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](cs1_practical_one-sample_files/figure-html/unnamed-chunk-5-1.png){width=672}\n:::\n:::\n\n\n## Choosing a test\n\nThere are two tests that we are going to look at in this situation; the one-sample t-test, and the one-sample Wilcoxon signed rank-sum test. Both tests work on the sort of data that we're considering here, but they both have different assumptions.\n\nIf your data is normally distributed, then a one-sample t-test is appropriate. If your data aren't normally distributed, but their distribution is symmetric, and the sample size is small then a one-sample Wilcoxon signed rank-sum test is more appropriate.\n\nFor each statistical test we consider there will be five tasks. These will come back again and again, so pay extra close attention.\n\n::: callout-important\n1.  Setting out of the hypothesis\n2.  Summarise and visualisation of the data\n3.  Assessment of assumptions\n4.  Implementation of the statistical test\n5.  Interpreting the output and presentation of results\n:::\n\nWe won't always carry these out in exactly the same order, but we will always consider each of the five tasks for every test.\n\n## Data and hypotheses\n\nFor example, suppose we measure the body lengths of male guppies (in mm) collected from the Guanapo River in Trinidad. We want to test whether the data support the hypothesis that the mean body is actually 20 mm. We form the following null and alternative hypotheses:\n\n-   $H_0$: The mean body length is equal to 20mm ($\\mu =$ 20).\n-   $H_1$: The mean body length is not equal to 20mm ($\\mu \\neq$ 20).\n\nWe will use a one-sample, two-tailed t-test to see if we should reject the null hypothesis or not.\n\n-   We use a **one-sample** test because we only have one sample.\n-   We use a **two-tailed** t-test because we want to know if our data suggest that the true (population) mean is different from 20 mm in either direction rather than just to see if it is greater than or less than 20 mm (in which case we would use a one-tailed test).\n-   We're using a **t-test** because we don't know any better yet and because I'm telling you to. We'll look at what the precise assumptions/requirements need to be in a moment.\n\nMake sure you have downloaded the data (see: [Data section](../setup.qmd)) and placed it within your working directory.\n\n::: {.panel-tabset group=\"language\"}\n## R\n\nFirst we load the relevant libraries:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# load tidyverse\nlibrary(tidyverse)\n```\n:::\n\n\nWe then read in the data and create a table containing the data.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# import the data\nfishlengthDF <- read_csv(\"data/CS1-onesample.csv\")\n\nfishlengthDF\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 29 × 3\n      id river   length\n   <dbl> <chr>    <dbl>\n 1     1 Guanapo   19.1\n 2     2 Guanapo   23.3\n 3     3 Guanapo   18.2\n 4     4 Guanapo   16.4\n 5     5 Guanapo   19.7\n 6     6 Guanapo   16.6\n 7     7 Guanapo   17.5\n 8     8 Guanapo   19.9\n 9     9 Guanapo   19.1\n10    10 Guanapo   18.8\n# ℹ 19 more rows\n```\n:::\n:::\n\n\nThe first line reads the data into R and creates an object called a **tibble**, which is a type of **data frame**. This data frame contains 3 columns: a unique `id`, `river` encoding the river and `length` with the measured guppy length.\n\n## Python\n\nWe then read the data in:\n\n\n::: {.cell}\n\n```{.python .cell-code}\n# load the data\nfishlength_py = pd.read_csv('data/CS1-onesample.csv')\n\n# inspect the data\nfishlength_py.head()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n   id    river  length\n0   1  Guanapo    19.1\n1   2  Guanapo    23.3\n2   3  Guanapo    18.2\n3   4  Guanapo    16.4\n4   5  Guanapo    19.7\n```\n:::\n:::\n\n:::\n\n## Summarise and visualise\n\nSummarise the data and visualise it:\n\n::: {.panel-tabset group=\"language\"}\n## R\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsummary(fishlengthDF)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n       id        river               length    \n Min.   : 1   Length:29          Min.   :11.2  \n 1st Qu.: 8   Class :character   1st Qu.:17.5  \n Median :15   Mode  :character   Median :18.8  \n Mean   :15                      Mean   :18.3  \n 3rd Qu.:22                      3rd Qu.:19.7  \n Max.   :29                      Max.   :23.3  \n```\n:::\n:::\n\n\nFrom the `summary()` output we can see that the mean and median of the `length` variable are quite close together. The `id` column also has minimum, maximum, mean etc. values - these are not useful! The numbers in the `id` column have no numerical value, but are just to ensure each observation can be traced back, if needed.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(fishlengthDF,\n       aes(x = river,\n           y = length)) +\n  geom_boxplot()\n```\n\n::: {.cell-output-display}\n![](cs1_practical_one-sample_files/figure-html/unnamed-chunk-10-1.png){width=672}\n:::\n:::\n\n\n## Python\n\nFirst we have a look at a numerical summary of the data:\n\n\n::: {.cell}\n\n```{.python .cell-code}\nfishlength_py.describe()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n              id     length\ncount  29.000000  29.000000\nmean   15.000000  18.296552\nstd     8.514693   2.584636\nmin     1.000000  11.200000\n25%     8.000000  17.500000\n50%    15.000000  18.800000\n75%    22.000000  19.700000\nmax    29.000000  23.300000\n```\n:::\n:::\n\n\nFrom the `describe()` output we can see that the mean and median of the `length` variable are quite close together. The `id` column also has minimum, maximum, mean etc. values - these are not useful! The numbers in the `id` column have no numerical value, but are just to ensure each observation can be traced back, if needed.\n\n\n::: {.cell}\n\n```{.python .cell-code}\n(ggplot(fishlength_py,\n        aes(x = 'river',\n            y = 'length')) +\n     geom_boxplot())\n```\n\n::: {.cell-output-display}\n![](cs1_practical_one-sample_files/figure-html/unnamed-chunk-12-1.png){width=614}\n:::\n:::\n\n:::\n\nThe data do not appear to contain any obvious errors, and whilst both the mean and median are less than 20 (18.3 and 18.8 respectively) it is not absolutely certain that the sample mean is sufficiently different from this value to be \"statistically significant\", although we may anticipate such a result.\n\n## Assumptions\n\nWhen it comes to one-sample tests, we have two options:\n\na.  t-test\nb.  Wilcoxon signed-rank test\n\nFor us to use a t-test for this analysis (and for the results to be valid) we have to make two assumptions:\n\n1.  The parent distribution from which the sample is taken is normally distributed (and as such the sample data are normally distributed themselves).\n\n::: callout-note\nIt is worth noting though that the t-test is actually pretty robust in situations where the sample data are not normal. For sufficiently large sample sizes (your guess is as good as mine, but conventionally this means about 30 data points), you can use a t-test without worrying about whether the underlying population is normally distributed or not.\n:::\n\n2.  Each data point in the sample is independent of the others. This is in general not something that can be tested for and instead has to be considered from the sampling procedure. For example, taking repeated measurements from the same individual would generate data that are not independent.\n\nThe second point we know nothing about and so we ignore it here (this is an issue that needs to be considered from the experimental design), whereas the first assumption can be checked. There are three ways of checking for normality:\n\nIn increasing order of rigour, we have\n\n1.  Histogram\n2.  Quantile-quantile plot\n3.  Shapiro-Wilk test\n\n### Histogram of the data\n\nPlot a histogram of the data, which gives:\n\n::: {.panel-tabset group=\"language\"}\n## R\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(fishlengthDF,\n       aes(x = length)) +\n  geom_histogram(bins = 15)\n```\n\n::: {.cell-output-display}\n![](cs1_practical_one-sample_files/figure-html/unnamed-chunk-13-3.png){width=672}\n:::\n:::\n\n\n## Python\n\n\n::: {.cell}\n\n```{.python .cell-code}\n(ggplot(fishlength_py,\n        aes(x = \"length\")) +\n     geom_histogram(bins = 15))\n```\n\n::: {.cell-output-display}\n![](cs1_practical_one-sample_files/figure-html/unnamed-chunk-14-1.png){width=614}\n:::\n:::\n\n:::\n\nThe distribution appears to be uni-modal and symmetric, and so it isn't obviously non-normal. However, there are a lot of distributions that have these simple properties but which aren't normal, so this isn't exactly rigorous. Thankfully there are other, more rigorous tests.\n\nNB. By even looking at this distribution to assess the assumption of normality we are already going far beyond what anyone else ever does. Nevertheless, we will continue.\n\n### Q-Q plot of the data\n\nQ-Q plot is the short for quantile-quantile plot. This **diagnostic** plot (as it is sometimes called) is a way of comparing two distributions. How Q-Q plots work won't be explained here but will be addressed in the next session.\n\nConstruct a Q-Q Plot of the quantiles of the data against the quantiles of a normal distribution:\n\n::: {.panel-tabset group=\"language\"}\n## R\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(fishlengthDF,\n       aes(sample = length)) +\n  stat_qq() +\n  stat_qq_line(colour = \"blue\")\n```\n\n::: {.cell-output-display}\n![](cs1_practical_one-sample_files/figure-html/unnamed-chunk-15-3.png){width=672}\n:::\n:::\n\n\n## Python\n\n\n::: {.cell}\n\n```{.python .cell-code}\n(ggplot(fishlength_py,\n        aes(sample = \"length\")) +\n     stat_qq() +\n     stat_qq_line(colour = \"blue\"))\n```\n\n::: {.cell-output-display}\n![](cs1_practical_one-sample_files/figure-html/unnamed-chunk-16-1.png){width=614}\n:::\n:::\n\n:::\n\nWhat is important to know is that if the data were normally distributed then all of the points should lie on (or close to) the diagonal line in this graph.\n\nIn this case, the points lie quite close to the line for the most part but the sample quantiles (points) from either end of the sample distribution are either smaller (below the line on the left) or larger (above the line on the right) than expected if they were supposed to be normally distributed. This suggests that the sample distribution is a bit more spread out than would be expected if it came from a normal distribution.\n\nIt is important to recognise that there isn't a simple unambiguous answer when interpreting these types of graph, in terms of whether the assumption of normality has been well met or not and instead it often boils down to a matter of experience.\n\nIt is a very rare situation indeed where the assumptions necessary for a test will be met unequivocally and a certain degree of personal interpretation is always needed. Here you have to ask yourself whether the data are normal \"enough\" for you to be confident in the validity of the test.\n\nBelow are four examples of QQ plots for different types of distributions:\n\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n::: {.cell-output-display}\n![](cs1_practical_one-sample_files/figure-html/unnamed-chunk-18-1.png){width=672}\n:::\n:::\n\n\nThese two graphs relate to 200 data points that have been drawn from a normal distribution. Even here you can see that the points do not all lie perfectly on the diagonal line in the QQ plot, and a certain amount of deviation at the top and bottom of the graph can happen just by chance (if I were to draw a different set of point then the graph would look slightly different).\n\n------------------------------------------------------------------------\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](cs1_practical_one-sample_files/figure-html/unnamed-chunk-19-1.png){width=672}\n:::\n:::\n\n\nThese two graphs relate to 200 data points that have been drawn from a uniform distribution. Uniform distributions are more condensed than normal distributions, and this is reflected in the QQ plot having a very pronounced S-shaped pattern to it (this is colloquially known as **snaking**).\n\n------------------------------------------------------------------------\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](cs1_practical_one-sample_files/figure-html/unnamed-chunk-20-1.png){width=672}\n:::\n:::\n\n\nThese two graphs relate to 200 data points that have been drawn from a t distribution. t distributions are more spread out than normal distributions, and this is reflected in the QQ plot again having a very pronounced S-shaped pattern to it, but this time the snaking is a reflection of that observed for the uniform distribution.\n\n------------------------------------------------------------------------\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](cs1_practical_one-sample_files/figure-html/unnamed-chunk-21-1.png){width=672}\n:::\n:::\n\n\nThese two graphs relate to 200 data points that have been drawn from an exponential distribution. Exponential distributions are not symmetric and are very skewed compared with normal distributions. The significant right-skew in this distribution is reflected in the QQ plot again having points that curve away above the diagonal line at both ends (a left-skew would have the points being below the line at both ends).\n\nIn all four cases it is worth noting that the deviations are only at the ends of the plot.\n\n### Shapiro-Wilk test\n\nThis is one of a number of formal statistical test that assess whether a given sample of numbers come from a normal distribution. It calculates the probability of getting the sample data if the underlying distribution is in fact normal. It is very easy to carry out in R.\n\nPerform a Shapiro-Wilk test on the data:\n\n::: {.panel-tabset group=\"language\"}\n## R\n\nThe `shapiro.test()` function needs a numerical vector as input. We get this by extracting the `length` column.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nshapiro.test(fishlengthDF$length)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\tShapiro-Wilk normality test\n\ndata:  fishlengthDF$length\nW = 0.94938, p-value = 0.1764\n```\n:::\n:::\n\n\n-   The 1st line gives the name of the test and the `data:` tells you which data are used.\n-   The 3rd line contains the two key outputs from the test:\n-   The calculated W-statistic is 0.9494 (we don't need to know this)\n-   The p-value is 0.1764\n\n## Python\n\nWe take the `length` values from the `fishlength_py` data frame and pass that to the `normality()` function in `pingouin`:\n\n\n::: {.cell}\n\n```{.python .cell-code}\npg.normality(fishlength_py.length)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n               W      pval  normal\nlength  0.949384  0.176418    True\n```\n:::\n:::\n\n\n-   the `W` column gives us the W-statistic\n-   the `pval` column gives us the p-value\n-   the `normal` column gives us the outcome of the test in `True/False`\n:::\n\nAs the p-value is bigger than 0.05 (say) then we can say that there is insufficient evidence to reject the null hypothesis that the sample came from a normal distribution.\n\nIt is important to recognise that the Shapiro-Wilk test is not without limitations. It is rather sensitive to the sample size being considered. In general, for small sample sizes, the test is very relaxed about normality (and nearly all data sets are considered normal), whereas for large sample sizes the test can be overly strict, and it can fail to recognise data sets that are very nearly normal indeed.\n\n### Assumptions overview\n\n::: callout-important\nIn terms of assessing the assumptions of a test it is always worth considering several methods, both graphical and analytic, and not just relying on a single method.\n:::\n\nIn the `fishlength` example, the graphical Q-Q plot analysis was not especially conclusive as there was some suggestion of snaking in the plots, but the Shapiro-Wilk test gave a non-significant p-value (0.1764). Putting these two together, along with the original histogram and the recognition that there were only 30 data points in the data set I personally would be happy that the assumptions of the t-test were met well enough to trust the result of the t-test, but you may not be...\n\nIn which case we would consider an alternative test that has less stringent assumptions (but is less powerful): the [one-sample Wilcoxon signed-rank test](#cs1-onesample-wilcoxon-signed-rank).\n\n## Implement and interpret the test\n\nPerform a one-sample, two-tailed t-test:\n\n::: {.panel-tabset group=\"language\"}\n## R\n\n\n::: {.cell}\n\n```{.r .cell-code}\nt.test(fishlengthDF$length,\n       mu = 20, alternative = \"two.sided\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\tOne Sample t-test\n\ndata:  fishlengthDF$length\nt = -3.5492, df = 28, p-value = 0.001387\nalternative hypothesis: true mean is not equal to 20\n95 percent confidence interval:\n 17.31341 19.27969\nsample estimates:\nmean of x \n 18.29655 \n```\n:::\n:::\n\n\n-   The first argument must be a numerical vector of data values. In our case it's the `length` values.\n-   The second argument must be a number and is the mean to be tested under the null hypothesis.\n-   The third argument gives the type of alternative hypothesis and must be one of `two.sided`, `greater` or `less`. We have no prior assumptions on whether the alternative fish length would be greater or less than 20, so we choose `two.sided`.\n\nIn the output:\n\n-   The 1st line gives the name of the test and the 2nd line reminds you what the dataset was called\n-   The 3rd line contains the three key outputs from the test:\n    -   The calculated t-value is -3.5492 (we'll need this for reporting)\n    -   There are 28 degrees of freedom (again we'll need this for reporting)\n    -   The p-value is 0.001387.\n-   The 4th line simply states the alternative hypothesis\n-   The 5th and 6th lines give the 95th confidence interval (we don't need to know this)\n-   The 7th, 8th and 9th lines give the sample mean again (18.29655).\n\n## Python\n\n\n::: {.cell}\n\n```{.python .cell-code}\npg.ttest(x = fishlength_py.length,\n         y = 20,\n         alternative = \"two-sided\").round(3)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n            T  dof alternative  p-val           CI95%  cohen-d    BF10  power\nT-test -3.549   28   two-sided  0.001  [17.31, 19.28]    0.659  25.071  0.929\n```\n:::\n:::\n\n\n-   the `x` argument must be a numerical series of data values\n-   the `y` argument must be a number and is the mean to be tested under the null hypothesis\n-   the `alternative` argument defines the alternative hypothesis (we have no expectation that the fish length is smaller or larger than 20, if the null hypothesis does not hold up)\n-   with `.round(3)` we're rounding the outcome to 3 digits\n\nIn the output:\n\nWe're not focussing on *all* of the output just yet, but\n\n-   `T` gives us the value of the t-statistic\n-   `dof` gives us the degrees of freedom (we'll need this for reporting)\n-   `pval` gives us the p-value\n:::\n\nThe p-value is what we're mostly interested in. It gives the probability of us getting a sample such as ours if the null hypothesis were actually true.\n\n::: callout-important\n## p-value interpretation\n\n-   a high p-value means that there is a high probability of observing a sample such as ours and the null hypothesis is probably true whereas\n-   a low p-value means that there is a low probability of observing a sample such as ours and the null hypothesis is probably not true.\n\nIt is important to realise that the p-value is just an indication and there is no absolute certainty here in this interpretation.\n\nPeople, however like more definite answers and so we pick an artificial probability threshold (called a significance level) in order to be able to say something more decisive. The standard significance level is 0.05 and since our p-value is smaller than this we choose to say that \"it is very unlikely that we would have this particular sample if the null hypothesis were true\".\n:::\n\nIn this case the p-value is much smaller than 0.05, so we reject our null hypothesis and state that:\n\n> A one-sample t-test indicated that the mean body length of male guppies ($\\bar{x}$ = 18.29mm) differs significantly from 20 mm (p = 0.0014).\n\nThe above sentence is an adequate concluding statement for this test and is what we would write in any paper or report. Note that we have included (in brackets) information on the actual mean value of our group($\\bar{x}$ = 18.29mm) and the p-value (p = 0.0014). In some journals you are only required to report whether the p-value is less than the critical value (e.g. p \\< 0.05) but I would always recommend reporting the actual p-value obtained.\n\n::: callout-important\nAdditional information, such as the test statistic and degrees of freedom, are sometimes also reported. This is more of a legacy from the time where people did the calculations by hand and used tables. I personally find it much more useful to report as above and supply the data and analysis, so other people can see what I've done and why!\n:::\n\n## Dealing with non-normal data\n\nYour data might not always be normally distributed. That's not a huge issue and there are statistical tests that can deal with this. For a one-sample data set there is the Wilcoxon signed rank test. This test, in contrast to the one-sample t-test does not assume that the parent distribution is normally distributed. We do still need the parent distribution (and consequently the sample) to be the same shape and scale.\n\nThe Wilcoxon signed rank test checks if the rank-transformed values are symmetric around the median. As such, using this test we look to see if the *median* of the parent distributions differs significantly from a given hypothesised value (in contrast with the t-test that looks at the *mean*).\n\n### Data and hypotheses\n\nAgain, we use the `fishlength` data set. The one-sample Wilcoxon signed rank test allows to see if the *median* body length is different from a specified value. Here we want to test whether the data support the hypothesis that the median body is actually 20 mm. The following null and alternative hypotheses are very similar to those used for the one sample t-test:\n\n-   $H_0$: The median body length is equal to 20 mm ($\\mu =$ 20).\n-   $H_1$: The median body length is not equal to 20 mm ($\\mu \\neq$ 20).\n\nWe will use a one-sample, two-tailed Wilcoxon signed rank test to see if we should reject the null hypothesis or not.\n\n### Summarise and visualise\n\nWe did this before in the previous section, nothing really should have changed between now and then (if it has then you're not off to a good start on this practical!)\n\n### Assumptions\n\nIn order to use a one-sample Wilcoxon signed rank test for this analysis (and for the results to be strictly valid) we have to make two assumptions:\n\n1.  The data are distributed symmetrically around the median\n2.  Each data point in the sample is independent of the others. This is the same as for the t-test and is a common feature of nearly all statistical tests. Lack of independence in your data is really tough to deal with (if not impossible) and a large part of proper experimental design is ensuring this.\n\nWhilst there are formal statistical tests for symmetry we will opt for a simple visual inspection using both a box plot and a histogram.\n\nPlot a histogram and a box plot of the data:\n\n::: {.panel-tabset group=\"language\"}\n## R\n\nLet's first determine the median, so we can use that to compare our data to. We'll also store the value in an object called `median_fishlength`.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# determine the median\nmedian_fishlength <- median(fishlengthDF$length)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# create a histogram\nfishlengthDF %>% \n  ggplot(aes(x = length)) +\n  geom_histogram(bins = 10) +\n  geom_vline(xintercept = median_fishlength,\n             colour = \"red\")\n```\n\n::: {.cell-output-display}\n![](cs1_practical_one-sample_files/figure-html/unnamed-chunk-27-1.png){width=672}\n:::\n\n```{.r .cell-code}\n# create box plot\nfishlengthDF %>% \n  ggplot(aes(y = length)) +\n  geom_boxplot()\n```\n\n::: {.cell-output-display}\n![](cs1_practical_one-sample_files/figure-html/unnamed-chunk-27-2.png){width=672}\n:::\n:::\n\n\n## Python\n\nLet's first determine the median, so we can use that to compare our data to.\n\n\n::: {.cell}\n\n```{.python .cell-code}\nmedian_fishlength = fishlength_py.length.median()\n```\n:::\n\n::: {.cell}\n\n```{.python .cell-code}\n# create a histogram\n(ggplot(fishlength_py,\n        aes(x = \"length\")) +\n     geom_histogram(bins = 10) +\n     geom_vline(xintercept = median_fishlength,\n                colour = \"red\"))\n```\n\n::: {.cell-output-display}\n![](cs1_practical_one-sample_files/figure-html/unnamed-chunk-29-1.png){width=614}\n:::\n\n```{.python .cell-code}\n# create box plot\n(ggplot(fishlength_py,\n        aes(x = 1,\n            y = \"length\")) +\n     geom_boxplot())\n```\n\n::: {.cell-output-display}\n![](cs1_practical_one-sample_files/figure-html/unnamed-chunk-29-2.png){width=614}\n:::\n:::\n\n:::\n\nHere we can see that whilst the distribution isn't perfectly symmetric, neither is it heavily skewed to the left or right and we can make the call that the distribution is *symmetric enough* for us to be happy with the results of the test.\n\n### Implement and interpret the test\n\nPerform a one-sample, two-tailed Wilcoxon signed rank test:\n\n::: {.panel-tabset group=\"language\"}\n## R\n\n\n::: {.cell}\n\n```{.r .cell-code}\nwilcox.test(fishlengthDF$length,\n            mu = 20, alternative = \"two.sided\")\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning in wilcox.test.default(fishlengthDF$length, mu = 20, alternative =\n\"two.sided\"): cannot compute exact p-value with ties\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\tWilcoxon signed rank test with continuity correction\n\ndata:  fishlengthDF$length\nV = 67.5, p-value = 0.001222\nalternative hypothesis: true location is not equal to 20\n```\n:::\n:::\n\n\nThe syntax is identical to the one-sample t-test we carried out earlier.\n\n-   The first argument must be a numerical vector of data values.\n\n-   The second argument must be a number and is the median to be tested under the null hypothesis.\n\n-   The third argument gives the type of alternative hypothesis and must be one of `two.sided`, `greater` or `less.`\n\n-   The first line gives a warning (not an error) message regarding the implementation of this test. This can be safely ignored in this case as the p-value is so small, but essentially, it's letting you know that some of the data values are identical to each other. This is not supposed to happen as we should be dealing with continuous data for this test, but in practice it's not something that we need to worry ourselves with.\n\n-   It then gives you the name of the test and `data:` reminds you what the data set was called (here it's the numerical `length` values coming from the pipe)\n\n-   Next are the two key outputs from the test:\n\n    -   The calculated V statistic is 67.5\n    -   The p-value is 0.001222.\n\n-   The last line simply states the alternative hypothesis\n\n## Python\n\n\n::: {.cell}\n\n```{.python .cell-code}\npg.wilcoxon(fishlength_py.length - 20,\n            alternative = \"two-sided\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n          W-val alternative     p-val       RBC  CLES\nWilcoxon   67.5   two-sided  0.000669 -0.689655   NaN\n```\n:::\n:::\n\n\nThe syntax is similar to what we did earlier:\n\n-   The 1st argument we give to the `wilcoxon()` function is an array of the differences between our data points and the median to be tested under the null hypothesis, i.e. our data points (`fishlength_py.length`) minus the test median (20, in this case).\n-   The 2nd argument gives us the type of alternative hypothesis and must be one of \"two-sided\", \"larger\", or \"smaller\".\n:::\n\nAgain, the p-value is what we're most interested in. It gives the probability of us getting a sample such as ours if the null hypothesis were actually true. So, in this case since our p-value is less than 0.05 we can reject our null hypothesis and state that:\n\n> A one-sample Wilcoxon signed rank test indicated that the median body length of male guppies ($\\tilde{x}$ = 18.8 mm) differs significantly from 20 mm (p = 0.0012).\n\nThe above sentence is an adequate concluding statement for this test and is what we would write in any paper or report. Note that we have included (in brackets) information on the median value of the group ($\\tilde{x}$ = 18.8 mm) and the p-value (p = 0.0012). Keep in mind that, when publishing, you'd also submit your data and scripts, so people can follow your analysis.\n\n## Exercises\n\n### Gastric juices {#sec-exr_gastric}\n\n:::{.callout-exercise}\n\n{{< level 2 >}}\n\n\n\nThe following data are the dissolving times (in seconds) of a drug in agitated gastric juice:\n\n`42.7, 43.4, 44.6, 45.1, 45.6, 45.9, 46.8, 47.6`\n\nThese data are stored in `data/CS1-gastric_juices.csv`.\n\nDo these results provide any evidence to suggest that dissolving time for this drug is different from 45 seconds?\n\n1.  Here the data are already formatted for your convenience into a [tidy](https://cran.r-project.org/web/packages/tidyr/vignettes/tidy-data.html) format\n2.  Load the data from `data/CS1-gastric_juices.csv`\n3.  Write down the null and alternative hypotheses.\n4.  Summarise and visualise the data and perform an appropriate one-sample t-test.\n    -   What can you say about the dissolving time? (what sentence would you use to report this)\n5.  Check the assumptions for the test.\n    -   Was the test valid?\n\n::: {.callout-answer collapse=\"true\"}\n## Answer\n\n#### Hypotheses\n\n$H_0$ : mean $=$ 45s\n\n$H_1$ : mean $\\neq$ 45s\n\n#### Data, summarise & visualise\n\nWe read in the data from `CS1-gastric_juices.csv`. It contains two columns, an `id` column and a `dissolving_time` column with the measured values.\n\n::: {.panel-tabset group=\"language\"}\n## R\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# load the data\ndissolving <- read_csv(\"data/CS1-gastric_juices.csv\")\n\n# have a look at the data\ndissolving\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 8 × 2\n     id dissolving_time\n  <dbl>           <dbl>\n1     1            42.7\n2     2            43.4\n3     3            44.6\n4     4            45.1\n5     5            45.6\n6     6            45.9\n7     7            46.8\n8     8            47.6\n```\n:::\n\n```{.r .cell-code}\n# summarise the data\nsummary(dissolving)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n       id       dissolving_time\n Min.   :1.00   Min.   :42.70  \n 1st Qu.:2.75   1st Qu.:44.30  \n Median :4.50   Median :45.35  \n Mean   :4.50   Mean   :45.21  \n 3rd Qu.:6.25   3rd Qu.:46.12  \n Max.   :8.00   Max.   :47.60  \n```\n:::\n:::\n\n\nWe can look at the histogram and box plot of the data:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# create a histogram\nggplot(dissolving,\n       aes(x = dissolving_time)) +\n  geom_histogram(bins = 4)\n```\n\n::: {.cell-output-display}\n![](cs1_practical_one-sample_files/figure-html/unnamed-chunk-33-1.png){width=672}\n:::\n\n```{.r .cell-code}\n# create a boxplot\nggplot(dissolving,\n       aes(y = dissolving_time)) +\n  geom_boxplot()\n```\n\n::: {.cell-output-display}\n![](cs1_practical_one-sample_files/figure-html/unnamed-chunk-33-2.png){width=672}\n:::\n:::\n\n\n## Python\n\n\n::: {.cell}\n\n```{.python .cell-code}\n# load the data\ndissolving_py = pd.read_csv(\"data/CS1-gastric_juices.csv\")\n\n# have a look at the data\ndissolving_py.head()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n   id  dissolving_time\n0   1             42.7\n1   2             43.4\n2   3             44.6\n3   4             45.1\n4   5             45.6\n```\n:::\n\n```{.python .cell-code}\n# summarise the data\ndissolving_py.describe()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n            id  dissolving_time\ncount  8.00000         8.000000\nmean   4.50000        45.212500\nstd    2.44949         1.640068\nmin    1.00000        42.700000\n25%    2.75000        44.300000\n50%    4.50000        45.350000\n75%    6.25000        46.125000\nmax    8.00000        47.600000\n```\n:::\n:::\n\n\nWe can look at the histogram and box plot of the data:\n\n\n::: {.cell}\n\n```{.python .cell-code}\n# create a histogram\n(ggplot(dissolving_py,\n        aes(x = \"dissolving_time\")) +\n     geom_histogram(bins = 4))\n```\n\n::: {.cell-output-display}\n![](cs1_practical_one-sample_files/figure-html/unnamed-chunk-35-1.png){width=614}\n:::\n:::\n\n::: {.cell}\n\n```{.python .cell-code}\n# create a box plot\n(ggplot(dissolving_py,\n        aes(x = 1,\n            y = \"dissolving_time\")) +\n     geom_boxplot())\n```\n\n::: {.cell-output-display}\n![](cs1_practical_one-sample_files/figure-html/unnamed-chunk-36-3.png){width=614}\n:::\n:::\n\n\nPython (or `plotnine` in particular) gets a bit cranky if you try to create a `geom_boxplot` but do not define the `x` aesthetic. Hence us putting it as `1`. The value has no numerical meaning, however.\n:::\n\nThere are only 8 data points, so the histogram is rather uninformative. Thankfully the box plot is a bit more useful here. We can see:\n\n1.  There don't appear to be any major errors in data entry and there aren't any huge outliers\n2.  The median value in the box-plot (the thick black line) is pretty close to 45 and so I wouldn't be surprised if the mean of the data isn't significantly different from 45. We can confirm that by looking at the mean and median values that we calculated using the summary command from earlier.\n3.  The data appear to be symmetric, and so whilst we can't tell if they're normal they're a least not massively skewed.\n\n#### Assumptions\n\nNormality:\n\n::: {.panel-tabset group=\"language\"}\n## R\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# perform Shapiro-Wilk test\nshapiro.test(dissolving$dissolving_time)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\tShapiro-Wilk normality test\n\ndata:  dissolving$dissolving_time\nW = 0.98023, p-value = 0.9641\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# create a Q-Q plot\nggplot(dissolving,\n       aes(sample = dissolving_time)) +\n  stat_qq() +\n  stat_qq_line(colour = \"blue\")\n```\n\n::: {.cell-output-display}\n![](cs1_practical_one-sample_files/figure-html/unnamed-chunk-38-1.png){width=672}\n:::\n:::\n\n\n## Python\n\n\n::: {.cell}\n\n```{.python .cell-code}\n# Perform Shapiro-Wilk test to check normality\npg.normality(dissolving_py.dissolving_time)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n                        W      pval  normal\ndissolving_time  0.980234  0.964054    True\n```\n:::\n:::\n\n::: {.cell}\n\n```{.python .cell-code}\n# Create a Q-Q plot\n(ggplot(dissolving_py,\n        aes(sample = \"dissolving_time\")) +\n     stat_qq() +\n     stat_qq_line(colour = \"blue\"))\n```\n\n::: {.cell-output-display}\n![](cs1_practical_one-sample_files/figure-html/unnamed-chunk-40-1.png){width=614}\n:::\n:::\n\n:::\n\n-   The Shapiro test has a p-value of 0.964 which (given that it is bigger than 0.05) suggests that the data are normal enough.\n-   The Q-Q plot isn't perfect, with some deviation of the points away from the line but since the points aren't accelerating away from the line and, since we only have 8 points, we can claim, with some slight reservations, that the assumption of normality appears to be adequately well met.\n\nOverall, we are somewhat confident that the assumption of normality is well-enough met for the t-test to be an appropriate method for analysing the data. Note the ridiculous number of caveats here and the slightly political/slippery language I'm using. This is intentional and reflects the ambiguous nature of assumption checking. This is an important approach to doing statistics that you need to embrace.\n\nIn reality, if I found myself in this situation I would also try doing a non-parametric test on the data (Wilcoxon signed-rank test) and see whether I get the same conclusion about whether the median dissolving time differs from 45s. Technically, you don't know about the Wilcoxon test yet as you haven't done that section of the materials. Anyway, if I get the same conclusion then my confidence in the result of the test goes up considerably; it doesn't matter how well an assumption has been met, I get the same result. If on the other hand I get a completely different conclusion from carrying out the non-parametric test then all bets are off; I now have very little confidence in my test result as I don't know which one to believe (in the case that the assumptions of the test are a bit unclear). In this example a Wilcoxon test also gives us a non-significant result and so all is good.\n\n#### Implement test\n\n::: {.panel-tabset group=\"language\"}\n## R\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# perform one-sample t-test\nt.test(dissolving$dissolving_time,\n       mu = 45, alternative = \"two.sided\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\tOne Sample t-test\n\ndata:  dissolving$dissolving_time\nt = 0.36647, df = 7, p-value = 0.7248\nalternative hypothesis: true mean is not equal to 45\n95 percent confidence interval:\n 43.84137 46.58363\nsample estimates:\nmean of x \n  45.2125 \n```\n:::\n:::\n\n\n## Python\n\n\n::: {.cell}\n\n```{.python .cell-code}\npg.ttest(x = dissolving_py.dissolving_time,\n         y = 45,\n         alternative = \"two-sided\").round(3)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n            T  dof alternative  p-val           CI95%  cohen-d   BF10  power\nT-test  0.366    7   two-sided  0.725  [43.84, 46.58]     0.13  0.356  0.062\n```\n:::\n:::\n\n:::\n\n> A one-sample t-test indicated that the mean dissolving time of the drug is not significantly different from 45s ($\\bar{x}$ = 45.2, p = 0.725).\n\nAnd that, is that.\n:::\n:::\n\n### Gastric juices (revisited) {#sec-exr_gastricrevisit}\n\n:::{.callout-exercise}\n\n\n{{< level 2 >}}\n\n\n\nWhat if we were unsure if we could assume normality here? In that case we'd have to perform a Wilcoxon signed rank test.\n\n1.  Analyse the drug data set from before using a one-sample Wilcoxon signed rank test\n2.  Discuss with a (virtual) neighbour which of the two tests you feel is best suited to the data.\n3.  Does it matter in this case?\n\n::: {.callout-tip collapse=\"true\"}\n## Answer\n\n#### Hypotheses\n\n$H_0$ : median $=$ 45s\n\n$H_1$ : median $\\neq$ 45s\n\n#### Assumptions\n\nFrom the box plot from the previous exercise we already know that the data are symmetric enough for the test to be valid.\n\n#### Wilcoxon signed rank test\n\nCalculating the median and performing the test:\n\n::: {.panel-tabset group=\"language\"}\n## R\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmedian(dissolving$dissolving_time)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 45.35\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nwilcox.test(dissolving$dissolving_time,\n            mu = 45, alternative = \"two.sided\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\tWilcoxon signed rank exact test\n\ndata:  dissolving$dissolving_time\nV = 22, p-value = 0.6406\nalternative hypothesis: true location is not equal to 45\n```\n:::\n:::\n\n\n## Python\n\n\n::: {.cell}\n\n```{.python .cell-code}\ndissolving_py.dissolving_time.median()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n45.35\n```\n:::\n:::\n\n::: {.cell}\n\n```{.python .cell-code}\npg.wilcoxon(dissolving_py.dissolving_time - 45,\n            alternative = \"two-sided\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n          W-val alternative     p-val       RBC  CLES\nWilcoxon   14.0   two-sided  0.640625  0.222222   NaN\n```\n:::\n:::\n\n:::\n\n> A one-sample Wilcoxon-signed rank test indicated that the median dissolving time of the drug is not significantly different from 45 s ($\\tilde{x}$ = 45.35 , p = 0.64)\n\n#### Discussion\n\nIn terms of choosing between the two test we can see that both meet their respective assumptions and so both tests are valid. In this case both tests also agree in terms of their conclusions i.e. that the average dissolving time (either mean or median) doesn't differ significantly from the proposed value of 45 s.\n\n-   So one answer would be that it doesn't matter which test you use.\n-   Another answer would be that you should pick the test that measures the quantity you're interested in *i.e.* if you care about medians then use the Wilcoxon test, whereas if you care about means then use the t-test.\n-   A final answer would be that, since both test are valid we would prefer to use the test with greater **power**. t-tests always have more power than Wilcoxon tests (as long as they're valid) and so we could report that one. (We'll talk about this in the last session but power is effectively the capacity of a test to detect a significant difference - so more power is better).\n:::\n:::\n\n## Summary\n\n::: {.callout-tip}\n#### Key points\n\n-   One-sample tests are used when you have a single sample of continuous data\n-   The t-test assumes that the data are normally distributed and independent of each other\n-   A good way of assessing the assumption of normality is by checking the data against a Q-Q plot\n-   The Wilcoxon signed rank test is used when you have a single sample of continuous data, which is not normally distributed\n:::\n",
    "supporting": [
      "cs1_practical_one-sample_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}