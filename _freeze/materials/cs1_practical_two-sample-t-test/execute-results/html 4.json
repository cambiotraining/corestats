{
  "hash": "c39d3aaab8d47cb71878a3fff1e7b90f",
  "result": {
    "markdown": "---\ntitle: \"Student's t-test\"\n---\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n\n:::\n\n\n## Libraries and functions\n\n::: {.callout-note collapse=\"true\"}\n## Click to expand\n\n::: {.panel-tabset group=\"language\"}\n## tidyverse\n\n### Libraries\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# A collection of R packages designed for data science\nlibrary(tidyverse)\n\n# Converts stats functions to a tidyverse-friendly format\nlibrary(rstatix)\n```\n:::\n\n\n### Functions\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Computes summary statistics                         \nrstatix::get_summary_stats() \n\n# Performs Levene's test for equality of variance\n# (non-normally distributed data)\nrstatix::levene_test()\n\n# Performs Bartlett's test for equality of variance\n# (normally distributed data)\nstats::bartlett.test()\n\n# Plots a Q-Q plot for comparison with a normal distribution\nggplot2::stat_qq()\n\n# Adds a comparison line to the Q-Q plot\nggplot2::stat_qq_line()\n```\n:::\n\n\n## R\n\n### Libraries\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Companion to Applied Regression, provides additional\n# statistical functionality\nlibrary(car)\n```\n:::\n\n\n### Functions\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Splits the data into subsets, computes summary statistics\n# for each, and returns the result in a convenient form\nstats::aggregate()\n\n# Converts a stacked data frame into an unstacked data frame\n# (or a list if the lengths of the samples are different)\nutils::unstack()\n\n# Performs Bartlett's test for equality of variance\n# (normally distributed data)\nstats::bartlett.test()\n\n# Performs Levene's test for equality of variance\n# (non-normally distributed data)\ncar::leveneTest()\n\n# Performs a one-sample t-test, Student's t-test and Welch's t-test in later sections\nstats::t.test()\n\n# Plots a Q-Q plot for comparison with a normal distribution\nstats::qqnorm()\n\n# Adds a comparison line to the Q-Q plot\nstats::qqline()\n\n# Performs a Shapiro-Wilk test for normality\nstats::shapiro.test()\n```\n:::\n\n\n## Python\n\n| Libraries  | Description                                                              |\n|:---------------------|:-------------------------------------------------|\n| `plotnine` | The Python equivalent of `ggplot2`.                                      |\n| `pandas`   | A Python data analysis and manipulation tool.                            |\n| `pingouin` | A Python module developed to have simple yet exhaustive stats functions. |\n\n| Functions                                                                                                                      | Description                                                 |\n|:-----------------------------------|:-----------------------------------|\n| `pandas.DataFrame.read_csv`                                                                                                    | Reads in a `.csv` file                                      |\n| `pandas.DataFrame.head()`                                                                                                      | Plots the first few rows                                    |\n| `pandas.DataFrame.describe()`                                                                                                  | Gives summary statistics                                    |\n| `pandas.DataFrame.groupby()`                                                                                                   | Group DataFrame using a mapper or by a Series of columns    |\n| `pandas.DataFrame.query()`                                                                                                     | Query the columns of a DataFrame with a boolean expression  |\n| [`pingouin.normality()`](https://pingouin-stats.org/generated/pingouin.normality.html)                                         | Performs the Shapiro-Wilk test for normality.               |\n| [`pingouin.homoscedasticity()`](https://pingouin-stats.org/generated/pingouin.homoscedasticity.html#pingouin.homoscedasticity) | Checks for equality of variance.                            |\n| [`pingouin.ttest()`](https://pingouin-stats.org/generated/pingouin.ttest.html#pingouin.ttest)                                  | Performs a t-test                                           |\n| `plotnine.stats.stat_qq()`                                                                                                     | Plots a Q-Q plot for comparison with a normal distribution. |\n| `plotnine.stats.stat_qq_line()`                                                                                                | Adds a comparison line to the Q-Q plot.                     |\n:::\n:::\n\n## Data and hypotheses\n\nFor example, suppose we now measure the body lengths of male guppies (in mm) collected from two rivers in Trinidad; the Aripo and the Guanapo. We want to test whether the mean body length differs between samples. We form the following null and alternative hypotheses:\n\n-   $H_0$: The mean body length does not differ between the two groups $(\\mu A = \\mu G)$\n-   $H_1$: The mean body length does differ between the two groups $(\\mu A \\neq \\mu G)$\n\nWe use a two-sample, two-tailed t-test to see if we can reject the null hypothesis.\n\n-   We use a two-sample test because we now have two samples.\n-   We use a two-tailed t-test because we want to know if our data suggest that the true (population) means are different from one another rather than that one mean is specifically bigger or smaller than the other.\n-   We're using Student's t-test because the sample sizes are big and because we're assuming that the parent populations have equal variance (We can check this later).\n\nThe data are stored in the file `data/CS1-twosample.csv`.\n\nLet's read in the data and have a quick look at the first rows to see how the data is structured.\n\nMake sure you have downloaded the data (see: [Datasets](#index-datasets)) and placed it within your working directory.\n\n::: {.panel-tabset group=\"language\"}\n## tidyverse\n\nFirst we load the relevant libraries:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# load tidyverse\nlibrary(tidyverse)\n\n# load rstatix, a tidyverse-friendly stats package\nlibrary(rstatix)\n```\n:::\n\n\nWe then read in the data and create a table containing the data.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrivers <- read_csv(\"data/CS1-twosample.csv\")\n\nrivers\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 68 × 2\n   river   length\n   <chr>    <dbl>\n 1 Guanapo   19.1\n 2 Guanapo   23.3\n 3 Guanapo   18.2\n 4 Guanapo   16.4\n 5 Guanapo   19.7\n 6 Guanapo   16.6\n 7 Guanapo   17.5\n 8 Guanapo   19.9\n 9 Guanapo   19.1\n10 Guanapo   18.8\n# … with 58 more rows\n```\n:::\n:::\n\n\n## R\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrivers_r <- read.csv(\"data/CS1-twosample.csv\")\n\nhead(rivers_r)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n    river length\n1 Guanapo   19.1\n2 Guanapo   23.3\n3 Guanapo   18.2\n4 Guanapo   16.4\n5 Guanapo   19.7\n6 Guanapo   16.6\n```\n:::\n:::\n\n\n## Python\n\n\n::: {.cell}\n\n```{.python .cell-code}\nrivers_py = pd.read_csv(\"data/CS1-twosample.csv\")\n\nrivers_py.head()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n     river  length\n0  Guanapo    19.1\n1  Guanapo    23.3\n2  Guanapo    18.2\n3  Guanapo    16.4\n4  Guanapo    19.7\n```\n:::\n:::\n\n:::\n\n## Summarise and visualise {#cs1-students-sumvisual}\n\nLet's first summarise the data.\n\n::: {.panel-tabset group=\"language\"}\n## tidyverse\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsummary(rivers)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n    river               length     \n Length:68          Min.   :11.20  \n Class :character   1st Qu.:18.40  \n Mode  :character   Median :19.30  \n                    Mean   :19.46  \n                    3rd Qu.:20.93  \n                    Max.   :26.40  \n```\n:::\n:::\n\n\nThis gives us the standard summary statistics, but in this case we have more than one group (Aripo and Guanapo), so it might be helpful to get summary statistics *per group*. One way of doing this is by using the `get_summary_stats()` function from the `rstatix` library.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# get common summary stats for the length column\nrivers %>% \n  group_by(river) %>% \n  get_summary_stats(type = \"common\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 2 × 11\n  river   variable     n   min   max median   iqr  mean    sd    se    ci\n  <chr>   <chr>    <dbl> <dbl> <dbl>  <dbl> <dbl> <dbl> <dbl> <dbl> <dbl>\n1 Aripo   length      39  17.5  26.4   20.1   2.2  20.3  1.78 0.285 0.577\n2 Guanapo length      29  11.2  23.3   18.8   2.2  18.3  2.58 0.48  0.983\n```\n:::\n:::\n\n\nNumbers might not always give you the best insight into your data, so we also visualise our data:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrivers %>% \n  ggplot(aes(x = river, y = length)) +\n  geom_boxplot()\n```\n\n::: {.cell-output-display}\n![](cs1_practical_two-sample-t-test_files/figure-html/unnamed-chunk-13-1.png){width=672}\n:::\n:::\n\n\n## R\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsummary(rivers_r)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n    river               length     \n Length:68          Min.   :11.20  \n Class :character   1st Qu.:18.40  \n Mode  :character   Median :19.30  \n                    Mean   :19.46  \n                    3rd Qu.:20.93  \n                    Max.   :26.40  \n```\n:::\n:::\n\n\nThis gives us the standard summary statistics, but in this case we have more than one group (Aripo and Guanapo), so it might be helpful to get summary statistics *per group*. We can do this in base R using the `aggregate()` function.\n\n\n::: {.cell}\n\n```{.r .cell-code}\naggregate(length ~ river,\n          data = rivers_r,\n          summary)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n    river length.Min. length.1st Qu. length.Median length.Mean length.3rd Qu.\n1   Aripo    17.50000       19.10000      20.10000    20.33077       21.30000\n2 Guanapo    11.20000       17.50000      18.80000    18.29655       19.70000\n  length.Max.\n1    26.40000\n2    23.30000\n```\n:::\n:::\n\n\n-   The first argument defines the variable that is being used (`length`) and grouping (`river`)\n-   The second argument is the data frame that is used\n-   The third argument defines the function that is applied across the subsets (in this case that's the `summary()` function)\n\nNumbers might not always give you the best insight into your data, so we also visualise our data:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nboxplot(length ~ river,\n        data = rivers_r)\n```\n\n::: {.cell-output-display}\n![](cs1_practical_two-sample-t-test_files/figure-html/unnamed-chunk-16-1.png){width=672}\n:::\n:::\n\n\nWe can use a very similar notation as we did for the summary statistics (`length ~ river`), so a box plot is created per group.\n\n## Python\n\n\n::: {.cell}\n\n```{.python .cell-code}\nrivers_py.describe()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n          length\ncount  68.000000\nmean   19.463235\nstd     2.370081\nmin    11.200000\n25%    18.400000\n50%    19.300000\n75%    20.925000\nmax    26.400000\n```\n:::\n:::\n\n\nThis gives us the standard summary statistics, but in this case we have more than one group (Aripo and Guanapo), so it might be helpful to get summary statistics *per group*. Here we use the `pd.groupby()` function to group by `river`. We only want to have summary statistics for the `length` variable, so we specify that as well:\n\n\n::: {.cell}\n\n```{.python .cell-code}\nrivers_py.groupby(\"river\")[\"length\"].describe()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n         count       mean       std   min   25%   50%   75%   max\nriver                                                            \nAripo     39.0  20.330769  1.780620  17.5  19.1  20.1  21.3  26.4\nGuanapo   29.0  18.296552  2.584636  11.2  17.5  18.8  19.7  23.3\n```\n:::\n:::\n\n\nNumbers might not always give you the best insight into your data, so we also visualise our data:\n\n\n::: {.cell}\n\n```{.python .cell-code}\n(\n  ggplot(rivers_py, aes(x = \"river\", y = \"length\"))\n  + geom_boxplot()\n)\n```\n\n::: {.cell-output-display}\n![](cs1_practical_two-sample-t-test_files/figure-html/unnamed-chunk-19-1.png){width=614}\n:::\n:::\n\n:::\n\nThe box plot does appear to suggest that the two samples have different means, and moreover that the guppies in Guanapo may be smaller than the guppies in Aripo. It isn't immediately obvious that the two populations don't have equal variances though (box plots are not quite the right tool for this), so we plough on. Who ever said statistics would be glamorous?\n\n## Assumptions\n\nIn order to use a Student's t-test (and for the results to be strictly valid) we have to make three assumptions:\n\n1.  The parent distributions from which the samples are taken are both normally distributed (which would lead to the sample data being normally distributed too).\n2.  Each data point in the samples is independent of the others.\n3.  The parent distributions should have the same variance.\n\nIn this example the first assumption can be ignored as the sample sizes are large enough (because of maths, with Aripo containing 39 and Guanapo 29 samples). If the samples were smaller then we would use the tests from the previous section.\n\nThe second point we can do nothing about unless we know how the data were collected, so again we ignore it.\n\nThe third point regarding equality of variance can be tested using either Bartlett's test (if the samples are normally distributed) or Levene's test (if the samples are not normally distributed).\n\nThis is where it gets a bit trickier. Although we don't care if the samples are normally distributed for the t-test to be valid (because the sample size is big enough to compensate), we do need to know if they are normally distributed in order to decide which variance test to use.\n\nSo we perform a [Shapiro-Wilk test](#shapiro-wilk-test) on both samples separately.\n\n::: {.panel-tabset group=\"language\"}\n## tidyverse\n\nWe can use the `group_by()` function to group the data by `river`, then we perform the Shapiro-Wilk test on the `length` measurements:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# group data by river and perform test\nrivers %>% \n  group_by(river) %>% \n  shapiro_test(length)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 2 × 4\n  river   variable statistic      p\n  <chr>   <chr>        <dbl>  <dbl>\n1 Aripo   length       0.936 0.0280\n2 Guanapo length       0.949 0.176 \n```\n:::\n:::\n\n\n## R\n\nBefore we can do that, we need to convert the data to a format where the data is split by `river`:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# create a new object (a list) that contains the unstacked data\nuns_rivers <- unstack(rivers_r, form = length ~ river)\n# have a look at the data\nuns_rivers\n```\n:::\n\n\nNow that we've separated the data by river we can perform the Shapiro-Wilk test:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nshapiro.test(uns_rivers$Aripo)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\tShapiro-Wilk normality test\n\ndata:  uns_rivers$Aripo\nW = 0.93596, p-value = 0.02802\n```\n:::\n\n```{.r .cell-code}\nshapiro.test(uns_rivers$Guanapo)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\tShapiro-Wilk normality test\n\ndata:  uns_rivers$Guanapo\nW = 0.94938, p-value = 0.1764\n```\n:::\n:::\n\n\n## Python\n\nTo perform a Shapiro-Wilk test we can use the `normality()` function from `pingouin`. We can give it the data in the original 'long' format, where we specify:\n\n-   `dv` = dependent variable, `length`\n-   `group` = grouping variable, \\`river\n-   `data` = data frame\n\n\n::: {.cell}\n\n```{.python .cell-code}\npg.normality(dv = \"length\",\n             group = \"river\",\n             data = rivers_py)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n                W      pval  normal\nGuanapo  0.949384  0.176420    True\nAripo    0.935958  0.028023   False\n```\n:::\n:::\n\n:::\n\nWe can see that whilst the Guanapo data is probably normally distributed (p = 0.1764 \\> 0.05), the Aripo data is unlikely to be normally distributed (p = 0.02802 \\< 0.05). Remember that the p-value gives the probability of observing each sample if the parent population is actually normally distributed.\n\nThe Shapiro-Wilk test is quite sensitive to sample size. This means that if you have a large sample then even small deviations from normality will cause the sample to fail the test, whereas smaller samples are allowed to pass with much larger deviations. Here the Aripo data has nearly 40 points in it compared with the Guanapo data and so it is much easier for the Aripo sample to fail compared with the Guanapo data.\n\n## Exercise: Q-Q plots rivers {#exercise-qq-rivers}\n\nCreate the Q-Q plots for the two samples and discuss with your neighbour what you see in light of the results from the above Shapiro-Wilk test.\n\n::: {.callout-tip collapse=\"true\"}\n## Answer\n\n::: {.panel-tabset group=\"language\"}\n## tidyverse\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# we group the data by river\n# then create a panel per river\n# containing the Q-Q plot for that river\nrivers %>% \n  ggplot(aes(sample = length)) +\n  stat_qq() +\n  stat_qq_line(colour = \"red\") +\n  facet_wrap(facets = vars(river))\n```\n\n::: {.cell-output-display}\n![](cs1_practical_two-sample-t-test_files/figure-html/unnamed-chunk-22-1.png){width=672}\n:::\n:::\n\n\n## R\n\n\n::: {.cell}\n\n```{.r .cell-code}\npar(mfrow=c(1,2))\nqqnorm(uns_rivers$Aripo, main = \"Aripo\")\nqqline(uns_rivers$Aripo, col = \"red\")\n\nqqnorm(uns_rivers$Guanapo, main = \"Guanapo\")\nqqline(uns_rivers$Guanapo, col = \"red\")\n```\n\n::: {.cell-output-display}\n![](cs1_practical_two-sample-t-test_files/figure-html/unnamed-chunk-23-1.png){width=672}\n:::\n:::\n\n\n## Python\n\n\n::: {.cell}\n\n```{.python .cell-code}\n(\n  ggplot(rivers_py, aes(sample = \"length\"))\n  + stat_qq()\n  + stat_qq_line(colour = \"red\")\n  + facet_wrap(\"river\")\n)\n```\n\n::: {.cell-output-display}\n![](cs1_practical_two-sample-t-test_files/figure-html/unnamed-chunk-24-1.png){width=614}\n:::\n:::\n\n:::\n\nThe Q-Q plots show the opposite of what we found with the Shapiro-Wilk tests: the data for Aripo look pretty normally distributed, whereas the assumption of normality for the Guanapo data is less certain.\n\nWhat to do? Well, you could be conservative and state that you are not confident that the data in either group are normally distributed. That would be a perfectly reasonable conclusion.\n\nI would personally not have issues with stating that the Aripo data are probably normally distributed *enough*.\n:::\n\n## Equality of variance\n\n::: callout-tip\nRemember that statistical tests do not provide answers, they merely suggest patterns. Human interpretation is still a crucial aspect to what we do.\n:::\n\nThe reason why we're checking for equality of variance (also referred to as **homogeneity of variance**) is because many statistical tests assume that the spread of the data within different parental populations (in this case, two) is the same.\n\nIf that is indeed the case, then the data themselves should have equal spread as well.\n\nThe Shapiro-Wilk test and the Q-Q plots have shown that some of the data might not be normal *enough* (although in opposite directions!) and so in order to test for equality of variance we will use Levene's test.\n\n::: {.panel-tabset group=\"language\"}\n## tidyverse\n\nThe function we use is `levene_test()` from the `rstatix` library.\n\nIt takes the data in the form of a formula as follows:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrivers %>% \n  levene_test(length ~ river)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 1 × 4\n    df1   df2 statistic     p\n  <int> <int>     <dbl> <dbl>\n1     1    66      1.77 0.188\n```\n:::\n:::\n\n\nThe key bit of information is the `p` column. This is the p-value (0.1876) for this test.\n\n## R\n\nLevene's test is not included in the default R packages and may require the installation of an additional package called `car` (Companion to Applied Regression).\n\nTo install the `car` package, run the following command in your console:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ninstall.packages(\"car\")\n```\n:::\n\n\nAlternatively, go to <kbd>Tools</kbd> \\> <kbd>Install packages...</kbd> \\> <kbd>Packages</kbd>, type in `car` and press <kbd>Install</kbd>\n\nWe can now perform Levene's test:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nleveneTest(length ~ river, data = rivers)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nLevene's Test for Homogeneity of Variance (center = median)\n      Df F value Pr(>F)\ngroup  1  1.7732 0.1876\n      66               \n```\n:::\n:::\n\n\nIgnore any warning you might get about coercion to factors (the test needs to create grouped variables to work and R versions from 4.x onwards do not read in the data as factors).\n\nThe key bit of information is the 3rd line under the text `Pr(>F)`. This is the p-value for this test.\n\n## Python\n\nTo test for equality of variance, we can use the `homoscedasticity()` function from `pingouin`.\n\nNote that, contrary to R, we specify the type of test in the `method` argument. The default is `\"levene\"`, assuming that data are *not* normally distributed.\n\n\n::: {.cell}\n\n```{.python .cell-code}\npg.homoscedasticity(dv = \"length\",\n                    group = \"river\",\n                    method = \"levene\",\n                    data = rivers_py)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n               W      pval  equal_var\nlevene  1.773184  0.187569       True\n```\n:::\n:::\n\n:::\n\nThe p-value tells us the probability of observing these two samples if they come from distributions with the same variance. As this probability is greater than our arbitrary significance level of 0.05 then we can be somewhat confident that the necessary assumptions for carrying out Student's t-test on these two samples was valid. (Once again woohoo!)\n\n### Bartlett's test\n\nIf we had wanted to carry out Bartlett's test (i.e. if the data *had* been sufficiently normally distributed) then we would have done:\n\n::: {.panel-tabset group=\"language\"}\n## tidyverse\n\nHere we use `bartlett.test()` from base R. Surprisingly, the `rstatix` package does not have a built-in equivalent.\n\nIf we wanted to get the output of the Bartlett test into a tidy format, we could do the following, where we take the `rivers` data set and pipe it to the `bartlett.test()` function. Note that we need to define the data using a dot (`.`), because the first input into `bartlett.test()` is not the data. We then pipe the output to the `tidy()` function, which is part of the `broom` library, which kindly converts the output into a tidy format. Handy!\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# load the broom package\nlibrary(broom)\n\n# perform Bartlett's test on the data and tidy\nrivers %>% \n  bartlett.test(length ~ river,\n                data = .) %>% \n  tidy()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 1 × 4\n  statistic p.value parameter method                                   \n      <dbl>   <dbl>     <dbl> <chr>                                    \n1      4.47  0.0344         1 Bartlett test of homogeneity of variances\n```\n:::\n:::\n\n\n## R\n\n\n::: {.cell}\n\n```{.r .cell-code}\nbartlett.test(length ~ river, data = rivers_r)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\tBartlett test of homogeneity of variances\n\ndata:  length by river\nBartlett's K-squared = 4.4734, df = 1, p-value = 0.03443\n```\n:::\n:::\n\n\nThe relevant p-value is given on the 3rd line.\n\n## Python\n\n\n::: {.cell}\n\n```{.python .cell-code}\npg.homoscedasticity(dv = \"length\",\n                    group = \"river\",\n                    method = \"bartlett\",\n                    data = rivers_py)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n                 T      pval  equal_var\nbartlett  4.473437  0.034426      False\n```\n:::\n:::\n\n:::\n\n## Implement and interpret the test\n\nIn this case we're ignoring the fact that the data are not normal enough, according to the Shapiro-Wilk test. However, this is not entirely naughty, because the sample sizes are pretty large and the t-test is also pretty robust in this case, we can perform a t-test. Remember, this is only allowed because the variances of the two groups (Aripo and Guanapo) are equal.\n\nPerform a two-sample, two-tailed, t-test:\n\n::: {.panel-tabset group=\"language\"}\n## tidyverse\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# two-sample, two-tailed t-test\nrivers %>% \n  t_test(length ~ river,\n         alternative = \"two.sided\",\n         var.equal = TRUE)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 1 × 8\n  .y.    group1 group2     n1    n2 statistic    df        p\n* <chr>  <chr>  <chr>   <int> <int>     <dbl> <dbl>    <dbl>\n1 length Aripo  Guanapo    39    29      3.84    66 0.000275\n```\n:::\n:::\n\n\nHere we do the following:\n\n-   We take the data set and pipe it to the `t_test()` function\n-   The `t_test()` function takes the formula in the format `variable ~ category`\n-   Again the alternative is `two.sided` because we have no prior knowledge about whether the alternative should be `greater` or `less`\n-   The last argument says whether the variance of the two samples can be assumed to be equal (Student's t-test) or unequal (Welch's t-test)\n\nSo, how do we interpret these results?\n\n-   The first 5 columns give you information on the variable (`.y.`), groups and sample size of each group\n-   The `statistic` column gives the t-value of 3.8433 (we need this for reporting)\n-   The `df` column tell us there are 66 degrees of freedom (we need this for reporting)\n-   The `p` column gives us a p-value of 0.0002754\n\n## R\n\n\n::: {.cell}\n\n```{.r .cell-code}\nt.test(length ~ river, data = rivers_r,\n       alternative = \"two.sided\",\n       var.equal = TRUE)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\tTwo Sample t-test\n\ndata:  length by river\nt = 3.8433, df = 66, p-value = 0.0002754\nalternative hypothesis: true difference in means between group Aripo and group Guanapo is not equal to 0\n95 percent confidence interval:\n 0.9774482 3.0909868\nsample estimates:\n  mean in group Aripo mean in group Guanapo \n             20.33077              18.29655 \n```\n:::\n:::\n\n\n-   The first argument must be in the formula format: `variables ~ category`\n-   The second argument must be the name of the data frame\n-   The third argument gives the type of alternative hypothesis and must be one of `two.sided`, `greater` or `less`\n-   The fourth argument says whether the variance of the two samples can be assumed to be equal (Student's t-test) or unequal (Welch's t-test)\n\nSo, how do we interpret the results?\n\n-   The 1st line gives the name of the test and the 2nd line reminds you what the data set was called, and what variables were used.\n-   The 3rd line contains the three key outputs from the test:\n    -   The calculated t-value is 3.8433 (we need this for reporting)\n    -   There are 66 degrees of freedom (we need this for reporting)\n    -   The p-value is 0.0002754.\n-   The 4th line simply states the alternative hypothesis in terms of the difference between the two sample means (testing if the two sample means are different is equivalent to testing whether the difference in the means is equal to zero).\n-   The 5th and 6th lines give the 95th confidence interval (we don't need to know this here).\n-   The 7th, 8th and 9th lines give the sample means for each group (20.33077 in Aripo and 18.29655 in Guanapo) which we found earlier.\n\n## Python\n\nThe `ttest()` function in `pingouin` needs two vectors as input, so we split the data as follows:\n\n\n::: {.cell}\n\n```{.python .cell-code}\naripo = rivers_py.query('river == \"Aripo\"')[\"length\"]\nguanapo = rivers_py.query('river == \"Guanapo\"')[\"length\"]\n```\n:::\n\n\nNext, we perform the t-test. We specify that the variance are equal by setting `correction = False`. We also `transpose()` the data, so we can actually see the entire output.\n\n\n::: {.cell}\n\n```{.python .cell-code}\npg.ttest(aripo, guanapo,\n         correction = False).transpose()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n                   T-test\nT                3.843267\ndof                    66\nalternative     two-sided\np-val            0.000275\nCI95%        [0.98, 3.09]\ncohen-d          0.942375\nBF10               92.191\npower            0.966135\n```\n:::\n:::\n\n:::\n\nAgain, the p-value is what we're most interested in. Since the p-value is very small (much smaller than the standard significance level) we choose to say \"that it is very unlikely that these two samples came from the same parent distribution and as such we can reject our null hypothesis\" and state that:\n\n> A Student's t-test indicated that the mean body length of male guppies in the Guanapo river (18.29 mm) differs significantly from the mean body length of male guppies in the Aripo river (20.33 mm) (t = 3.8433, df = 66, p = 0.0003).\n\n<br />\n\nNow there's a conversation starter.\n\n## Exercise: Turtles\n\nThis exercise explores serum cholesterol concentrations in turtles.\n\nUsing the following data, test the null hypothesis that male and female turtles have the same mean serum cholesterol concentrations.\n\n\n::: {.cell}\n::: {.cell-output-display}\n`````{=html}\n<table class=\"table table-striped\" style=\"width: auto !important; margin-left: auto; margin-right: auto;\">\n <thead>\n  <tr>\n   <th style=\"text-align:right;\"> id </th>\n   <th style=\"text-align:right;\"> Male </th>\n   <th style=\"text-align:right;\"> Female </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:right;\"> 1 </td>\n   <td style=\"text-align:right;\"> 220.1 </td>\n   <td style=\"text-align:right;\"> NA </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 2 </td>\n   <td style=\"text-align:right;\"> 218.6 </td>\n   <td style=\"text-align:right;\"> NA </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 3 </td>\n   <td style=\"text-align:right;\"> 229.6 </td>\n   <td style=\"text-align:right;\"> NA </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 4 </td>\n   <td style=\"text-align:right;\"> 228.8 </td>\n   <td style=\"text-align:right;\"> NA </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 5 </td>\n   <td style=\"text-align:right;\"> 222.0 </td>\n   <td style=\"text-align:right;\"> NA </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 6 </td>\n   <td style=\"text-align:right;\"> 224.1 </td>\n   <td style=\"text-align:right;\"> NA </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 7 </td>\n   <td style=\"text-align:right;\"> 226.5 </td>\n   <td style=\"text-align:right;\"> NA </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 8 </td>\n   <td style=\"text-align:right;\"> NA </td>\n   <td style=\"text-align:right;\"> 223.4 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 9 </td>\n   <td style=\"text-align:right;\"> NA </td>\n   <td style=\"text-align:right;\"> 221.5 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 10 </td>\n   <td style=\"text-align:right;\"> NA </td>\n   <td style=\"text-align:right;\"> 230.2 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 11 </td>\n   <td style=\"text-align:right;\"> NA </td>\n   <td style=\"text-align:right;\"> 224.3 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 12 </td>\n   <td style=\"text-align:right;\"> NA </td>\n   <td style=\"text-align:right;\"> 223.8 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 13 </td>\n   <td style=\"text-align:right;\"> NA </td>\n   <td style=\"text-align:right;\"> 230.8 </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n\n1.  Create a tidy data frame and save as a `.csv` file\n2.  Write down the null and alternative hypotheses\n3.  Import the data\n4.  Summarise and visualise the data\n5.  Check your assumptions (normality and variance) using appropriate tests and plots\n6.  Perform a two-sample t-test\n7.  Write down a sentence that summarises the results that you have found\n\n::: {.callout-tip collapse=\"true\"}\n## Answer\n\n### Data\n\nWe'll stop asking you to manually create your own data files soon, but it's meant to get you to think about how to record your data. If we're using a tidy data format, then each variable (thing that you measure) is in its own column. Each observation has its own row.\n\nThis means that if you would restructure the data from above it would look like this:\n\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nturtle\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 13 × 2\n   serum sex   \n   <dbl> <chr> \n 1  220. Male  \n 2  219. Male  \n 3  230. Male  \n 4  229. Male  \n 5  222  Male  \n 6  224. Male  \n 7  226. Male  \n 8  223. Female\n 9  222. Female\n10  230. Female\n11  224. Female\n12  224. Female\n13  231. Female\n```\n:::\n:::\n\n\n### Hypotheses\n\n$H_0$ : male mean $=$ female mean\n\n$H_1$ : male mean $\\neq$ female mean\n\n### Load, summarise and visualise data\n\nLet's load the data (I've created the `.csv` file earlier) and explore our data a bit more before we dive into the statistics.\n\n::: {.panel-tabset group=\"language\"}\n## tidyverse\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# load the data\nturtle <- read_csv(\"data/CS1-turtle.csv\")\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nRows: 13 Columns: 2\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (1): sex\ndbl (1): serum\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n```\n:::\n\n```{.r .cell-code}\n# and have a look\nturtle\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 13 × 2\n   serum sex   \n   <dbl> <chr> \n 1  220. Male  \n 2  219. Male  \n 3  230. Male  \n 4  229. Male  \n 5  222  Male  \n 6  224. Male  \n 7  226. Male  \n 8  223. Female\n 9  222. Female\n10  230. Female\n11  224. Female\n12  224. Female\n13  231. Female\n```\n:::\n:::\n\n\nLet's summarise the data (although a visualisation is probably much easier to work with):\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# create summary statistics for each group\nturtle %>% \n  group_by(sex) %>% \n  get_summary_stats(type = \"common\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 2 × 11\n  sex    variable     n   min   max median   iqr  mean    sd    se    ci\n  <chr>  <chr>    <dbl> <dbl> <dbl>  <dbl> <dbl> <dbl> <dbl> <dbl> <dbl>\n1 Female serum        6  222.  231.   224.  5.22  226.  3.87  1.58  4.06\n2 Male   serum        7  219.  230.   224.  6.6   224.  4.26  1.61  3.94\n```\n:::\n:::\n\n\nand visualise the data:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# visualise the data\nturtle %>% \n  ggplot(aes(x = sex, y = serum)) +\n  geom_boxplot()\n```\n\n::: {.cell-output-display}\n![](cs1_practical_two-sample-t-test_files/figure-html/unnamed-chunk-38-1.png){width=672}\n:::\n:::\n\n\n## R\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# load the data\nturtle_r <- read.csv(\"data/CS1-turtle.csv\")\n\n# and have a look\nhead(turtle_r)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n  serum  sex\n1 220.1 Male\n2 218.6 Male\n3 229.6 Male\n4 228.8 Male\n5 222.0 Male\n6 224.1 Male\n```\n:::\n:::\n\n\nand visualise the data:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# visualise the data\nboxplot(serum ~ sex , data = turtle_r)\n```\n\n::: {.cell-output-display}\n![](cs1_practical_two-sample-t-test_files/figure-html/unnamed-chunk-40-1.png){width=672}\n:::\n:::\n\n\n## Python\n\n\n::: {.cell}\n\n```{.python .cell-code}\nturtle_py = pd.read_csv(\"data/CS1-turtle.csv\")\n\nturtle_py.describe()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n            serum\ncount   13.000000\nmean   224.900000\nstd      3.978274\nmin    218.600000\n25%    222.000000\n50%    224.100000\n75%    228.800000\nmax    230.800000\n```\n:::\n:::\n\n\nand visualise the data:\n\n\n::: {.cell}\n\n```{.python .cell-code}\n(\n  ggplot(turtle_py, aes(x = \"sex\",\n                        y = \"serum\"))\n  + geom_boxplot()\n)\n```\n\n::: {.cell-output-display}\n![](cs1_practical_two-sample-t-test_files/figure-html/unnamed-chunk-42-1.png){width=614}\n:::\n:::\n\n:::\n\nAs always we use the plot and summary to assess three things:\n\n1.  Does it look like we've loaded the data in correctly?\n    -   We have two groups and the extreme values of our plots seem to match with our data set, so I'm happy that we haven't done anything massively wrong here.\n2.  Do we think that there is a difference between the two groups?\n    -   We need the result of the formal test to make sense given the data, so it's important to develop a sense of what we think is going to happen here. Whilst the ranges of the two groups suggests that the Female serum levels might be higher than the males when we look at things more closely we realise that isn't the case. The box plot shows that the median values of the two groups is virtually identical and this is backed up by the summary statistics we calculated: the medians are both about 224.1, and the means are fairly close too (225.7 vs 224.2). Based on this, and the fact that there are only 13 observations in total I would be very surprised if any test came back showing that there was a difference between the groups.\n3.  What do we think about assumptions?\n    -   Normality looks a bit worrying: whilst the `Male` group appears nice and symmetric (and so might be normal), the `Female` group appears to be quite skewed (since the median is much closer to the bottom than the top). We'll have to look carefully at the more formal checks to decided whether we think the data are normal enough for us to use a t-test.\n    -   Homogeneity of variance. At this stage the spread of the data within each group looks similar, but because of the potential skew in the `Female` group we'll again want to check the assumptions carefully.\n\n### Assumptions\n\n**Normality**\n\nLet's look at the normality of each of the groups separately. There are several ways of getting at the `serum` values for `Male` and `Female` groups separately. All of them come down to splitting the data. Afterwards we use the Shapiro-Wilk ('formal' test), followed by Q-Q plots (much more informative).\n\n::: {.panel-tabset group=\"language\"}\n## tidyverse\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# perform Shapiro-Wilk test on each group\nturtle %>% \n  group_by(sex) %>% \n  shapiro_test(serum)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 2 × 4\n  sex    variable statistic     p\n  <chr>  <chr>        <dbl> <dbl>\n1 Female serum        0.842 0.135\n2 Male   serum        0.944 0.674\n```\n:::\n:::\n\n\n## R\n\nWe can use the `unstack()` function to split the data, then access the relevant values.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nuns_turtle_r <- unstack(turtle_r, serum ~ sex)\n\nuns_turtle_r\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n$Female\n[1] 223.4 221.5 230.2 224.3 223.8 230.8\n\n$Male\n[1] 220.1 218.6 229.6 228.8 222.0 224.1 226.5\n```\n:::\n:::\n\n\nYou can see that the data has been split by `sex`.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nshapiro.test(uns_turtle_r$Male)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\tShapiro-Wilk normality test\n\ndata:  uns_turtle_r$Male\nW = 0.94392, p-value = 0.6743\n```\n:::\n\n```{.r .cell-code}\nshapiro.test(uns_turtle_r$Female)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\tShapiro-Wilk normality test\n\ndata:  uns_turtle_r$Female\nW = 0.84178, p-value = 0.1349\n```\n:::\n:::\n\n\n## Python\n\n\n::: {.cell}\n\n```{.python .cell-code}\nturtle_male = turtle_py.query('sex == \"Male\"')[\"serum\"]\nturtle_female = turtle_py.query('sex == \"Female\"')[\"serum\"]\n```\n:::\n\n::: {.cell}\n\n```{.python .cell-code}\npg.normality(dv = \"serum\",\n             group = \"sex\",\n             data = turtle_py)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n               W      pval  normal\nMale    0.943924  0.674275    True\nFemale  0.841785  0.134871    True\n```\n:::\n:::\n\n:::\n\nThe p-values for both Shapiro-Wilk tests are non-significant which suggests that the data are normal enough. This is a bit surprising given what we saw in the box plot but there are two bits of information that we can use to reassure us.\n\n1.  The p-value for the `Female` group is smaller than for the `Male` group (suggesting that the `Female` group is closer to being non-normal than the `Male` group) which makes sense based on our visual observations.\n2.  The Shapiro-Wilk test is generally quite relaxed about normality for small sample sizes (and notoriously strict for very large sample sizes). For a group with only 6 data points in it, the data would actually have to have a really, really skewed distribution. Given that the Female group only has 6 data points in it, it's not too surprising that the Shapiro-Wilk test came back saying everything is OK.\n\nGiven these caveats of the Shapiro-Wilk test (I'll stop mentioning them now, I think I've made my opinion clear ;)), let's look at the Q-Q plots.\n\n::: {.panel-tabset group=\"language\"}\n## tidyverse\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# create Q-Q plots for both groups\nturtle %>% \n  ggplot(aes(sample = serum)) +\n  stat_qq() +\n  stat_qq_line(colour = \"red\") +\n  facet_wrap(facets = vars(sex))\n```\n\n::: {.cell-output-display}\n![](cs1_practical_two-sample-t-test_files/figure-html/unnamed-chunk-48-1.png){width=672}\n:::\n:::\n\n\n## R\n\n\n::: {.cell}\n\n```{.r .cell-code}\npar(mfrow=c(1,2))\nqqnorm(uns_turtle_r$Female, main = \"Female\")\nqqline(uns_turtle_r$Female, col = \"red\")\nqqnorm(uns_turtle_r$Male, main = \"Male\")\nqqline(uns_turtle_r$Male, col = \"red\")\n```\n\n::: {.cell-output-display}\n![](cs1_practical_two-sample-t-test_files/figure-html/cs1-twosample-turtle-qqplot-1.png){width=672}\n:::\n:::\n\n\n## Python\n\n\n::: {.cell}\n\n```{.python .cell-code}\n# create Q-Q plots for both groups\n(\n  ggplot(turtle_py, aes(sample = \"serum\"))\n  + stat_qq()\n  + stat_qq_line(colour = \"red\")\n  + facet_wrap(\"sex\")\n)\n```\n\n::: {.cell-output-display}\n![](cs1_practical_two-sample-t-test_files/figure-html/unnamed-chunk-49-1.png){width=614}\n:::\n:::\n\n:::\n\nThe results from the Q-Q plots echo what we've already seen from the Shapiro-Wilk analyses. The normality of the data in the `Male` group doesn't look too bad whereas the those in the `Female` group looks somewhat dodgy.\n\nOverall, the assumption of normality of the data doesn't appear to be very well met at all, but we do have to bear in mind that there are only a few data points in each group and we might just be seeing this pattern in the data due to random chance rather than because the underlying populations are actually not normally distributed. Personally, though I'd edge towards non-normal here.\n\n**Homogeneity of Variance**\n\nIt's not clear whether the data are normal or not, so it isn't clear which test to use here. The sensible approach is to do both and hope that they agree (fingers crossed!). Or err on the side of caution and assume they are not normal, but potentially throwing away statistical power (more on that later).\n\n::: {.panel-tabset group=\"language\"}\n## tidyverse\n\nBartlett's test gives us:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# perform Bartlett's test\nbartlett.test(serum ~ sex,\n              data = turtle)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\tBartlett test of homogeneity of variances\n\ndata:  serum by sex\nBartlett's K-squared = 0.045377, df = 1, p-value = 0.8313\n```\n:::\n:::\n\n\nand Levene's test gives us:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# perform Levene's test\nturtle %>% \n  levene_test(serum ~ sex)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 1 × 4\n    df1   df2 statistic     p\n  <int> <int>     <dbl> <dbl>\n1     1    11     0.243 0.631\n```\n:::\n:::\n\n\n## R\n\nBartlett's test gives us:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nbartlett.test(serum ~ sex, turtle_r)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\tBartlett test of homogeneity of variances\n\ndata:  serum by sex\nBartlett's K-squared = 0.045377, df = 1, p-value = 0.8313\n```\n:::\n:::\n\n\nand Levene's test gives us:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# load if needed\n# library(car)\n\nleveneTest(serum ~ sex, turtle_r)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nLevene's Test for Homogeneity of Variance (center = median)\n      Df F value Pr(>F)\ngroup  1  0.2434 0.6315\n      11               \n```\n:::\n:::\n\n\n## Python\n\nBartlett's test gives us:\n\n\n::: {.cell}\n\n```{.python .cell-code}\npg.homoscedasticity(dv = \"serum\",\n                    group = \"sex\",\n                    method = \"bartlett\",\n                    data = turtle_py)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n                 T      pval  equal_var\nbartlett  0.045377  0.831312       True\n```\n:::\n:::\n\n\nand Levene's test gives us:\n\n\n::: {.cell}\n\n```{.python .cell-code}\npg.homoscedasticity(dv = \"serum\",\n                    group = \"sex\",\n                    method = \"levene\",\n                    data = turtle_py)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n               W     pval  equal_var\nlevene  0.243418  0.63145       True\n```\n:::\n:::\n\n:::\n\nThe good news is that both Levene and Bartlett agree that there is homogeneity of variance between the two groups (thank goodness, that's one less thing to worry about!).\n\nOverall, what this means is that we're not too sure about normality, but that homogeneity of variance is pretty good.\n\n### Implement two-sample t-test\n\nBecause of the result of the Bartlett test I know that I can carry out a two-sample Student's t-test. If the variances between the two groups were not equal, then we'd have to perform Welch's t-test.\n\n::: {.panel-tabset group=\"language\"}\n## tidyverse\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# perform two-sample t-test\nturtle %>% \n  t_test(serum ~ sex,\n         alternative = \"two.sided\",\n         var.equal = TRUE)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 1 × 8\n  .y.   group1 group2    n1    n2 statistic    df     p\n* <chr> <chr>  <chr>  <int> <int>     <dbl> <dbl> <dbl>\n1 serum Female Male       6     7     0.627    11 0.544\n```\n:::\n:::\n\n\n## R\n\n\n::: {.cell}\n\n```{.r .cell-code}\nt.test(serum ~ sex,\n       data = turtle_r,\n       alternative = \"two.sided\",\n       var.equal = TRUE)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\tTwo Sample t-test\n\ndata:  serum by sex\nt = 0.62681, df = 11, p-value = 0.5436\nalternative hypothesis: true difference in means between group Female and group Male is not equal to 0\n95 percent confidence interval:\n -3.575759  6.423378\nsample estimates:\nmean in group Female   mean in group Male \n            225.6667             224.2429 \n```\n:::\n:::\n\n\n## Python\n\n\n::: {.cell}\n\n```{.python .cell-code}\npg.ttest(turtle_female, turtle_male,\n                alternative = \"two-sided\",\n                correction = False).transpose()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n                    T-test\nT                 0.626811\ndof                     11\nalternative      two-sided\np-val             0.543573\nCI95%        [-3.58, 6.42]\ncohen-d           0.348725\nBF10                 0.519\npower             0.088495\n```\n:::\n:::\n\n:::\n\nWith a p-value of 0.544, this test tells me that there is insufficient evidence to suggest that the means of the two groups are different. A suitable summary sentence would be:\n\n> A Student's two-sample t-test indicated that the mean serum cholesterol level did not differ significantly between Male and Female turtles (t = 0.627, df = 11, p = 0.544).\n\n### Discussion\n\nIn reality, because of the ambiguous normality assumption assessment, for this data set I would actually carry out two different tests; the two-sample t-test with equal variance and the Mann-Whitney U test. If both of them agreed then it wouldn't matter too much which one I reported (I'd personally report both with a short sentence to say that I'm doing that because it wasn't clear whether the assumption of normality had or had not been met), but it would be acceptable to report just one.\n:::\n",
    "supporting": [
      "cs1_practical_two-sample-t-test_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<script src=\"../site_libs/kePrint-0.0.1/kePrint.js\"></script>\n<link href=\"../site_libs/lightable-0.0.1/lightable.css\" rel=\"stylesheet\" />\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}